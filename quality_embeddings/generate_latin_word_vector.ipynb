{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a WordVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging \n",
    "import multiprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG = logging.getLogger('make_word_vec')\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Parameter suggestions brought to you by:\n",
    " * Hyperparameters matter\n",
    " * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_characteristics = 'non_lemmatized'  \n",
    "# corpus_filename =  'latin_library.preprocessed.cor' \n",
    "\n",
    "corpus_characteristics = 'lemmatized'  \n",
    "corpus_filename ='latin_library.lemmatized.preprocessed.cor'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : Creating vector with parameters: {\"size\": 600, \"iter\": 300, \"min_count\": 2, \"max_vocab_size\": null, \"ns_exponent\": 0.75, \"alpha\": 0.025, \"min_alpha\": 0.004, \"sg\": 1, \"window\": 10, \"workers\": 7, \"negative\": 15, \"sample\": 512}\n",
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : PROGRESS: at sentence #10000, processed 175859 words, keeping 5879 word types\n",
      "INFO : PROGRESS: at sentence #20000, processed 342816 words, keeping 8001 word types\n",
      "INFO : PROGRESS: at sentence #30000, processed 550570 words, keeping 9757 word types\n",
      "INFO : PROGRESS: at sentence #40000, processed 753358 words, keeping 11368 word types\n",
      "INFO : PROGRESS: at sentence #50000, processed 969282 words, keeping 12523 word types\n",
      "INFO : PROGRESS: at sentence #60000, processed 1161725 words, keeping 13634 word types\n",
      "INFO : PROGRESS: at sentence #70000, processed 1344406 words, keeping 16515 word types\n",
      "INFO : PROGRESS: at sentence #80000, processed 1512472 words, keeping 21512 word types\n",
      "INFO : PROGRESS: at sentence #90000, processed 1737376 words, keeping 24509 word types\n",
      "INFO : PROGRESS: at sentence #100000, processed 1858271 words, keeping 25158 word types\n",
      "INFO : PROGRESS: at sentence #110000, processed 2004532 words, keeping 26521 word types\n",
      "INFO : PROGRESS: at sentence #120000, processed 2167419 words, keeping 28066 word types\n",
      "INFO : PROGRESS: at sentence #130000, processed 2330360 words, keeping 30493 word types\n",
      "INFO : PROGRESS: at sentence #140000, processed 2510236 words, keeping 31468 word types\n",
      "INFO : PROGRESS: at sentence #150000, processed 2671323 words, keeping 32242 word types\n",
      "INFO : PROGRESS: at sentence #160000, processed 2829223 words, keeping 33123 word types\n",
      "INFO : PROGRESS: at sentence #170000, processed 2986029 words, keeping 33797 word types\n",
      "INFO : PROGRESS: at sentence #180000, processed 3150261 words, keeping 34167 word types\n",
      "INFO : PROGRESS: at sentence #190000, processed 3302631 words, keeping 34425 word types\n",
      "INFO : PROGRESS: at sentence #200000, processed 3448329 words, keeping 35012 word types\n",
      "INFO : PROGRESS: at sentence #210000, processed 3637550 words, keeping 37195 word types\n",
      "INFO : PROGRESS: at sentence #220000, processed 3795333 words, keeping 38915 word types\n",
      "INFO : PROGRESS: at sentence #230000, processed 3955877 words, keeping 39929 word types\n",
      "INFO : PROGRESS: at sentence #240000, processed 4168474 words, keeping 41226 word types\n",
      "INFO : PROGRESS: at sentence #250000, processed 4389186 words, keeping 43405 word types\n",
      "INFO : PROGRESS: at sentence #260000, processed 4514331 words, keeping 44487 word types\n",
      "INFO : PROGRESS: at sentence #270000, processed 4654577 words, keeping 46466 word types\n",
      "INFO : PROGRESS: at sentence #280000, processed 4805578 words, keeping 47007 word types\n",
      "INFO : PROGRESS: at sentence #290000, processed 4959312 words, keeping 47551 word types\n",
      "INFO : PROGRESS: at sentence #300000, processed 5090051 words, keeping 47990 word types\n",
      "INFO : PROGRESS: at sentence #310000, processed 5224723 words, keeping 48490 word types\n",
      "INFO : PROGRESS: at sentence #320000, processed 5324898 words, keeping 48778 word types\n",
      "INFO : PROGRESS: at sentence #330000, processed 5480820 words, keeping 49283 word types\n",
      "INFO : PROGRESS: at sentence #340000, processed 5645987 words, keeping 49899 word types\n",
      "INFO : PROGRESS: at sentence #350000, processed 5834788 words, keeping 51675 word types\n",
      "INFO : PROGRESS: at sentence #360000, processed 6022328 words, keeping 53730 word types\n",
      "INFO : PROGRESS: at sentence #370000, processed 6221919 words, keeping 54961 word types\n",
      "INFO : PROGRESS: at sentence #380000, processed 6406486 words, keeping 55760 word types\n",
      "INFO : PROGRESS: at sentence #390000, processed 6628421 words, keeping 56635 word types\n",
      "INFO : PROGRESS: at sentence #400000, processed 6754994 words, keeping 57071 word types\n",
      "INFO : PROGRESS: at sentence #410000, processed 6965954 words, keeping 57988 word types\n",
      "INFO : PROGRESS: at sentence #420000, processed 7609855 words, keeping 60957 word types\n",
      "INFO : PROGRESS: at sentence #430000, processed 7770039 words, keeping 62258 word types\n",
      "INFO : PROGRESS: at sentence #440000, processed 7919731 words, keeping 64100 word types\n",
      "INFO : PROGRESS: at sentence #450000, processed 8032027 words, keeping 65388 word types\n",
      "INFO : PROGRESS: at sentence #460000, processed 8167714 words, keeping 66078 word types\n",
      "INFO : PROGRESS: at sentence #470000, processed 8326280 words, keeping 67174 word types\n",
      "INFO : PROGRESS: at sentence #480000, processed 8496749 words, keeping 68299 word types\n",
      "INFO : PROGRESS: at sentence #490000, processed 8681334 words, keeping 69964 word types\n",
      "INFO : PROGRESS: at sentence #500000, processed 8851541 words, keeping 71864 word types\n",
      "INFO : PROGRESS: at sentence #510000, processed 9038351 words, keeping 73419 word types\n",
      "INFO : PROGRESS: at sentence #520000, processed 9128434 words, keeping 74545 word types\n",
      "INFO : PROGRESS: at sentence #530000, processed 9212129 words, keeping 75541 word types\n",
      "INFO : PROGRESS: at sentence #540000, processed 9329305 words, keeping 76148 word types\n",
      "INFO : PROGRESS: at sentence #550000, processed 9537039 words, keeping 76449 word types\n",
      "INFO : PROGRESS: at sentence #560000, processed 9731036 words, keeping 76658 word types\n",
      "INFO : PROGRESS: at sentence #570000, processed 9894274 words, keeping 76884 word types\n",
      "INFO : PROGRESS: at sentence #580000, processed 10041113 words, keeping 77124 word types\n",
      "INFO : PROGRESS: at sentence #590000, processed 10208224 words, keeping 78263 word types\n",
      "INFO : collected 79260 word types from a corpus of 10277876 raw words and 593596 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : effective_min_count=2 retains 37221 unique words (46% of original 79260, drops 42039)\n",
      "INFO : effective_min_count=2 leaves 10235837 word corpus (99% of original 10277876, drops 42039)\n",
      "INFO : deleting the raw counts dictionary of 79260 items\n",
      "INFO : sample=512 downsamples 437 most-common words\n",
      "INFO : downsampling leaves estimated 5792870 word corpus (56.6% of prior 10235837)\n",
      "INFO : estimated required memory for 37221 words and 600 dimensions: 197271300 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 7 workers on 37221 vocabulary and 600 features, using sg=1 hs=0 sample=512 negative=15 window=10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-ac73d42c4f2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Creating vector with parameters: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlatin_lib_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeyword_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/ML-You-Can-Use/p37/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[0;32m~/PycharmProjects/ML-You-Can-Use/p37/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/ML-You-Can-Use/p37/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/ML-You-Can-Use/p37/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/ML-You-Can-Use/p37/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n\u001b[0;32m--> 556\u001b[0;31m                     corpus_file, cur_epoch=cur_epoch, total_examples=total_examples, total_words=total_words, **kwargs)\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mtrained_word_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrained_word_count_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/ML-You-Can-Use/p37/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch_corpusfile\u001b[0;34m(self, corpus_file, cur_epoch, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    432\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             total_examples=total_examples, total_words=total_words, is_corpus_file_mode=True)\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/ML-You-Can-Use/p37/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "keyword_params = {\n",
    "    'size': 600,\n",
    "    'iter': 300,\n",
    "    'min_count': 2, # Ignores all words with total frequency lower than this.\n",
    "    'max_vocab_size': None,\n",
    "    'ns_exponent': 0.75, # the default, optimal for linguistic tasks; also try -0.5 for recommenders\n",
    "    'alpha':  0.025,\n",
    "    'min_alpha': 0.004,\n",
    "    'sg': 1, # skip gram\n",
    "    'window': 10, # number of surrounding words to consider\n",
    "    'workers': multiprocessing.cpu_count() - 1,\n",
    "    'negative': 15, # 15 may be best\n",
    "    'sample': 0.001 #   0.00001  # sample=1e-05 downsamples 4158 most-common words\n",
    "    #     sample=0.001 downsamples 32 most-common words\n",
    "}\n",
    "LOG.info('Creating vector with parameters: %s', json.dumps(keyword_params))\n",
    "latin_lib_vec = Word2Vec(corpus_file=corpus_filename, **keyword_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : Saving word2vec for latin library corpus\n",
      "INFO : saving Word2Vec object under latin_library.non_lemmatized.2019.03.08.vec, separately None\n",
      "INFO : storing np array 'vectors' to latin_library.non_lemmatized.2019.03.08.vec.wv.vectors.npy\n",
      "INFO : not storing attribute vectors_norm\n",
      "INFO : storing np array 'syn1neg' to latin_library.non_lemmatized.2019.03.08.vec.trainables.syn1neg.npy\n",
      "INFO : not storing attribute cum_table\n",
      "INFO : saved latin_library.non_lemmatized.2019.03.08.vec\n"
     ]
    }
   ],
   "source": [
    "LOG.info('Saving word2vec for latin library corpus')\n",
    "latin_lib_vec.save('latin_library.{}.{}.vec'.format(corpus_characteristics, datetime.now().strftime('%Y.%m.%d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('latin_library.vec.{}.{}.params'.format(corpus_characteristics, datetime.now().strftime('%Y.%m.%d')), 'wt') as writer:\n",
    "    json.dump(keyword_params, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the word vectors to disk\n",
    "they should be cross platform, cross language loadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : saving Word2VecKeyedVectors object under latin_library.non_lemmatized.2019.03.08.kv, separately None\n",
      "INFO : storing np array 'vectors' to latin_library.non_lemmatized.2019.03.08.kv.vectors.npy\n",
      "INFO : not storing attribute vectors_norm\n",
      "INFO : saved latin_library.non_lemmatized.2019.03.08.kv\n"
     ]
    }
   ],
   "source": [
    "word_vectors = latin_lib_vec.wv\n",
    "the_filename = 'latin_library.{}.{}.kv'.format(corpus_characteristics, datetime.now().strftime('%Y.%m.%d'))\n",
    "word_vectors.save(the_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cacata', 0.40804749727249146),\n",
       " ('euellerat', 0.35726672410964966),\n",
       " ('scitula', 0.34938153624534607),\n",
       " ('trahetur', 0.3437250852584839),\n",
       " ('plebea', 0.3397197723388672),\n",
       " ('instabatur', 0.3371580243110657),\n",
       " ('succenses', 0.33677178621292114),\n",
       " ('sauio', 0.33424675464630127),\n",
       " ('concupiueris', 0.33303868770599365),\n",
       " ('ligustro', 0.33187466859817505)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('puella')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('et', 0.3993789255619049),\n",
       " ('fabrilem', 0.3965851962566376),\n",
       " ('conloquetur', 0.38349807262420654),\n",
       " ('dominus', 0.3774290084838867),\n",
       " ('dixit', 0.37603938579559326),\n",
       " ('mancupium', 0.37392544746398926),\n",
       " ('incolet', 0.3695604205131531),\n",
       " ('non', 0.36870378255844116),\n",
       " ('uociferabitur', 0.36849337816238403),\n",
       " ('atramentarium', 0.36640453338623047)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.similar_by_word('uir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flauom', 0.372098833322525),\n",
       " ('aperuerant', 0.37147045135498047),\n",
       " ('infligebant', 0.35610195994377136),\n",
       " ('inlisi', 0.35295096039772034),\n",
       " ('accusarat', 0.3477999269962311),\n",
       " ('obtruncauerunt', 0.3422698974609375),\n",
       " ('nudabat', 0.33932244777679443),\n",
       " ('diripiebat', 0.339178204536438),\n",
       " ('imperitans', 0.3288525342941284),\n",
       " ('occupauimus', 0.32780519127845764)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.similar_by_word('uiolenter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : loading Word2VecKeyedVectors object from latin_library.non_lemmatized.2019.03.08.kv\n",
      "INFO : loading vectors from latin_library.non_lemmatized.2019.03.08.kv.vectors.npy with mmap=r\n",
      "INFO : setting ignored attribute vectors_norm to None\n",
      "INFO : loaded latin_library.non_lemmatized.2019.03.08.kv\n"
     ]
    }
   ],
   "source": [
    "the_filename = 'latin_library.{}.{}.kv'.format(corpus_characteristics, datetime.now().strftime('%Y.%m.%d'))\n",
    "latin_word_vectors = KeyedVectors.load(the_filename, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('et', 0.3993789255619049),\n",
       " ('fabrilem', 0.3965851962566376),\n",
       " ('conloquetur', 0.38349807262420654),\n",
       " ('dominus', 0.3774290084838867),\n",
       " ('dixit', 0.37603938579559326),\n",
       " ('mancupium', 0.37392544746398926),\n",
       " ('incolet', 0.3695604205131531),\n",
       " ('non', 0.36870378255844116),\n",
       " ('uociferabitur', 0.36849337816238403),\n",
       " ('atramentarium', 0.36640453338623047)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_word_vectors.most_similar('uir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exprimebatur', 0.400768518447876),\n",
       " ('inuerecundus', 0.3843785226345062),\n",
       " ('letetur', 0.37862467765808105),\n",
       " ('adamatur', 0.3700706660747528),\n",
       " ('plantauerat', 0.36723676323890686),\n",
       " ('uir', 0.36512863636016846),\n",
       " ('factus', 0.3648669719696045),\n",
       " ('proselytis', 0.35976335406303406),\n",
       " ('choicus', 0.3569141626358032),\n",
       " ('nabla', 0.3554146885871887)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('homo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sonatur', 0.5754474401473999),\n",
       " ('bucinator', 0.3679332137107849),\n",
       " ('responsurium', 0.36166948080062866),\n",
       " ('consueuisset', 0.35109448432922363),\n",
       " ('momoriter', 0.34004682302474976),\n",
       " ('elimosinam', 0.3307771384716034),\n",
       " ('monochordo', 0.32640892267227173),\n",
       " ('conmoratus', 0.3229045569896698),\n",
       " ('frondiferas', 0.3085840344429016),\n",
       " ('cessarit', 0.3073081076145172)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('canere', topn=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('consurges', 0.3656068742275238),\n",
       " ('comesor', 0.35631316900253296),\n",
       " ('reticuisse', 0.35073623061180115),\n",
       " ('mendicabit', 0.33155322074890137),\n",
       " ('mergetur', 0.32906609773635864),\n",
       " ('ephippia', 0.32282310724258423),\n",
       " ('holitori', 0.31779569387435913),\n",
       " ('desidendo', 0.3161380887031555),\n",
       " ('debentibus', 0.30631572008132935),\n",
       " ('inpinguabitur', 0.29799818992614746)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('piger', topn=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gliscis', 0.3265058398246765),\n",
       " ('pulsantis', 0.2862904667854309),\n",
       " ('fruticeta', 0.2798694968223572),\n",
       " ('iactastis', 0.2630001902580261),\n",
       " ('eximendorum', 0.25384703278541565),\n",
       " ('lapsantibus', 0.25376540422439575),\n",
       " ('uibrent', 0.2533043920993805),\n",
       " ('erraretis', 0.24881130456924438),\n",
       " ('assulatim', 0.24873502552509308),\n",
       " ('frangentia', 0.24708648025989532)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('scandere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tenderemus', 0.487804114818573),\n",
       " ('gradienti', 0.48268240690231323),\n",
       " ('laeuorsus', 0.37227192521095276),\n",
       " ('austra', 0.31538620591163635),\n",
       " ('montanos', 0.3103235960006714),\n",
       " ('effecero', 0.3040349781513214),\n",
       " ('ferinas', 0.30135902762413025),\n",
       " ('remistheo', 0.3008953034877777),\n",
       " ('exorabant', 0.2989898920059204),\n",
       " ('despicimus', 0.29503586888313293)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('praelucere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hirundini', 0.3500634729862213),\n",
       " ('arrigis', 0.3463703989982605),\n",
       " ('uerpa', 0.32565271854400635),\n",
       " ('ducenties', 0.32386505603790283),\n",
       " ('luctaris', 0.2973496615886688),\n",
       " ('pedico', 0.28964224457740784),\n",
       " ('pedicaris', 0.28842228651046753),\n",
       " ('sesquipedalis', 0.2832435369491577),\n",
       " ('meiere', 0.2773906886577606),\n",
       " ('cunnus', 0.2743661403656006)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.similar_by_word('mentula')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('effregisti', 0.4355214238166809),\n",
       " ('serenanti', 0.4327419400215149),\n",
       " ('bacchium', 0.36393025517463684),\n",
       " ('flectendus', 0.3540099561214447),\n",
       " ('romanus', 0.3519400954246521),\n",
       " ('bibliopola', 0.3463898301124573),\n",
       " ('multiscius', 0.34309887886047363),\n",
       " ('fumea', 0.3318007290363312),\n",
       " ('aequaeuus', 0.3301989734172821),\n",
       " ('architectatus', 0.3297162652015686)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.similar_by_word('ciuis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : loading Word2VecKeyedVectors object from latin_library.2019.03.07.kv\n",
      "INFO : setting ignored attribute vectors_norm to None\n",
      "INFO : loaded latin_library.2019.03.07.kv\n"
     ]
    }
   ],
   "source": [
    "the_lemmatized_filename = 'latin_library.2019.03.07.kv' \n",
    "lem_lat_wordvec = KeyedVectors.load(the_lemmatized_filename, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('puer', 0.5749707818031311),\n",
       " ('iuuenis', 0.5151010751724243),\n",
       " ('uirgo', 0.49944934248924255),\n",
       " ('soror', 0.4523782730102539),\n",
       " ('mater', 0.45129919052124023),\n",
       " ('amare', 0.4469846189022064),\n",
       " ('uxor', 0.44040897488594055),\n",
       " ('maritus', 0.43844184279441833),\n",
       " ('at', 0.4366375207901001),\n",
       " ('coniunx', 0.4324739873409271)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_lat_wordvec.most_similar('puella')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mater', 0.6095702052116394),\n",
       " ('iuuenis', 0.5838768482208252),\n",
       " ('puella', 0.5749707818031311),\n",
       " ('ille', 0.5479326248168945),\n",
       " ('ludere', 0.535244345664978),\n",
       " ('senex', 0.519166111946106),\n",
       " ('uirgo', 0.5188031196594238),\n",
       " ('at', 0.5050873756408691),\n",
       " ('ferre', 0.504031240940094),\n",
       " ('parare', 0.5006879568099976)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_lat_wordvec.most_similar('puer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quum,142\r\n",
      "pol,117\r\n",
      "siet,96\r\n",
      "coss,86\r\n",
      "analogia,78\r\n",
      "que,77\r\n",
      "abi,74\r\n",
      "ite,64\r\n",
      "eccum,62\r\n",
      "hactenus,62\r\n"
     ]
    }
   ],
   "source": [
    "! head unglossed.fixed.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'eccum' in lem_lat_wordvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eccam', 0.525143027305603),\n",
       " ('attat', 0.49384814500808716),\n",
       " ('popli', 0.44641977548599243),\n",
       " ('scibo', 0.414834201335907),\n",
       " ('surrupta', 0.41333162784576416),\n",
       " ('sycophantiam', 0.3958692252635956),\n",
       " ('quoia', 0.39479494094848633),\n",
       " ('uidulo', 0.39022475481033325),\n",
       " ('optume', 0.38850533962249756),\n",
       " ('erus', 0.38483574986457825)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_lat_wordvec.most_similar('eccum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
