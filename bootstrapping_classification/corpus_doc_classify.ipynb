{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boostrapping Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Plain\n",
      "Doctest mode is: ON\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%doctest_mode on\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') # quiet warnings for presentation purposes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cltk.corpus.readers import FilteredPlaintextCorpusReader, get_corpus_reader\n",
    "# from cltk.corpus.latin.latin_library_corpus_types import  corpus_directories_by_type, corpus_texts_by_type  \n",
    "\n",
    "from cltk.prosody.latin.string_utils import punctuation_for_spaces_dict\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "from cltk.tokenize.sentence import TokenizeSentence\n",
    "from cltk.prosody.latin.scansion_constants import ScansionConstants\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing.label import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add parent directory to path so we can access our common code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlyoucanuse.doc2tokens_transformer import Doc2TokensTransformer\n",
    "from mlyoucanuse.corpus_fun import get_file_type_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample: opo Dunstano, vere moribus et aetate maturo, Abbo Floriacensis monachus levita, etsi indignus, a Chr\n"
     ]
    }
   ],
   "source": [
    "reader = get_corpus_reader(corpus_name='latin_text_latin_library', language='latin')\n",
    "ALL_FILE_IDS = list(reader.fileids() )\n",
    "print(f'All file ids: {len(ALL_FILE_IDS)} e.g.: {ALL_FILE_IDS[:5]}')\n",
    "print(f'Random sample: {list(reader.docs(ALL_FILE_IDS[2]))[0][200:300]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label some data, but not all \n",
    "#### requires some expertise, such as consulting:\n",
    "#### https://en.wikipedia.org/wiki/Classical_Latin \n",
    "#### https://en.wikipedia.org/wiki/Latin_literature\n",
    "### Create a dictionary of Category Types and a List of Instances, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "corpus_directories_by_type = {\n",
    "\n",
    "    'republican': [\n",
    "        './caesar',\n",
    "        './lucretius',\n",
    "        './nepos',\n",
    "        './cicero'\n",
    "    ],\n",
    "    'augustan': [\n",
    "        './livy',\n",
    "        './ovid',\n",
    "        './horace',\n",
    "        './vergil',\n",
    "        './hyginus',\n",
    "    ],\n",
    "    'early_silver': [\n",
    "        './martial',\n",
    "        './juvenal',\n",
    "        './tacitus',\n",
    "        './lucan',\n",
    "        './quintilian',\n",
    "        './sen',\n",
    "        './statius',\n",
    "        './silius',\n",
    "        './columella'\n",
    "    ],\n",
    "    'late_silver': [\n",
    "        './suetonius',\n",
    "        './gellius',\n",
    "        './apuleius'\n",
    "        './justin',\n",
    "        './apicius',\n",
    "        './fulgentius',\n",
    "        './orosius',\n",
    "    ],\n",
    "    'old': [\n",
    "        './plautus'\n",
    "    ],\n",
    "    'christian': [\n",
    "        './ambrose',\n",
    "        './abelard',\n",
    "        './alcuin',\n",
    "        './augustine',\n",
    "        './bede',\n",
    "        './bible',\n",
    "        './cassiodorus',\n",
    "        './commodianus',\n",
    "        './gregorytours',\n",
    "        './hugo',\n",
    "        './isidore',\n",
    "        './jerome',\n",
    "        './prudentius',\n",
    "        './tertullian',\n",
    "        './kempis',\n",
    "        './leothegreat',\n",
    "    ],\n",
    "    'medieval': [\n",
    "        './boethiusdacia',\n",
    "        './dante',\n",
    "    ],\n",
    "    'renaissance': [\n",
    "    ],\n",
    "    'neo_latin': [\n",
    "        './addison',\n",
    "        './bacon',\n",
    "        './bultelius',\n",
    "        './descartes',\n",
    "        './erasmus',\n",
    "        './galileo',\n",
    "        './kepler',\n",
    "        './may',\n",
    "        './melanchthon',\n",
    "        './xylander',\n",
    "        './campion',\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "#### by text\n",
    "\n",
    "\n",
    "corpus_texts_by_type = {\n",
    "    'republican': [\n",
    "        'sall.1.txt',\n",
    "        'sall.2.txt',\n",
    "        'sall.cotta.txt',\n",
    "        'sall.ep1.txt',\n",
    "        'sall.ep2.txt',\n",
    "        'sall.frag.txt',\n",
    "        'sall.invectiva.txt',\n",
    "        'sall.lep.txt',\n",
    "        'sall.macer.txt',\n",
    "        'sall.mithr.txt',\n",
    "        'sall.phil.txt',\n",
    "        'sall.pomp.txt',\n",
    "        'varro.frag.txt',\n",
    "        'varro.ll10.txt',\n",
    "        'varro.ll5.txt',\n",
    "        'varro.ll6.txt',\n",
    "        'varro.ll7.txt',\n",
    "        'varro.ll8.txt',\n",
    "        'varro.ll9.txt',\n",
    "        'varro.rr1.txt',\n",
    "        'varro.rr2.txt',\n",
    "        'varro.rr3.txt',\n",
    "        'sulpicia.txt',\n",
    "    ],\n",
    "    'augustan': [\n",
    "        'resgestae.txt',\n",
    "        'resgestae1.txt',\n",
    "        'manilius1.txt',\n",
    "        'manilius2.txt',\n",
    "        'manilius3.txt',\n",
    "        'manilius4.txt',\n",
    "        'manilius5.txt',\n",
    "        'catullus.txt',\n",
    "        'vitruvius1.txt',\n",
    "        'vitruvius10.txt',\n",
    "        'vitruvius2.txt',\n",
    "        'vitruvius3.txt',\n",
    "        'vitruvius4.txt',\n",
    "        'vitruvius5.txt',\n",
    "        'vitruvius6.txt',\n",
    "        'vitruvius7.txt',\n",
    "        'vitruvius8.txt',\n",
    "        'vitruvius9.txt',\n",
    "        'propertius1.txt',\n",
    "        'tibullus1.txt',\n",
    "        'tibullus2.txt',\n",
    "        'tibullus3.txt',\n",
    "    ],\n",
    "    'early_silver': [\n",
    "        'pliny.ep1.txt',\n",
    "        'pliny.ep10.txt',\n",
    "        'pliny.ep2.txt',\n",
    "        'pliny.ep3.txt',\n",
    "        'pliny.ep4.txt',\n",
    "        'pliny.ep5.txt',\n",
    "        'pliny.ep6.txt',\n",
    "        'pliny.ep7.txt',\n",
    "        'pliny.ep8.txt',\n",
    "        'pliny.ep9.txt',\n",
    "        'pliny.nh1.txt',\n",
    "        'pliny.nh2.txt',\n",
    "        'pliny.nh3.txt',\n",
    "        'pliny.nh4.txt',\n",
    "        'pliny.nh5.txt',\n",
    "        'pliny.nhpr.txt',\n",
    "        'pliny.panegyricus.txt',\n",
    "        'petronius1.txt',\n",
    "        'petroniusfrag.txt',\n",
    "        'persius.txt',\n",
    "        'phaedr1.txt',\n",
    "        'phaedr2.txt',\n",
    "        'phaedr3.txt',\n",
    "        'phaedr4.txt',\n",
    "        'phaedr5.txt',\n",
    "        'phaedrapp.txt',\n",
    "        'seneca.contr1.txt',\n",
    "        'seneca.contr10.txt',\n",
    "        'seneca.contr2.txt',\n",
    "        'seneca.contr3.txt',\n",
    "        'seneca.contr4.txt',\n",
    "        'seneca.contr5.txt',\n",
    "        'seneca.contr6.txt',\n",
    "        'seneca.contr7.txt',\n",
    "        'seneca.contr8.txt',\n",
    "        'seneca.contr9.txt',\n",
    "        'seneca.fragmenta.txt',\n",
    "        'seneca.suasoriae.txt',\n",
    "        'valeriusflaccus1.txt',\n",
    "        'valeriusflaccus2.txt',\n",
    "        'valeriusflaccus3.txt',\n",
    "        'valeriusflaccus4.txt',\n",
    "        'valeriusflaccus5.txt',\n",
    "        'valeriusflaccus6.txt',\n",
    "        'valeriusflaccus7.txt',\n",
    "        'valeriusflaccus8.txt',\n",
    "        'valmax1.txt',\n",
    "        'valmax2.txt',\n",
    "        'valmax3.txt',\n",
    "        'valmax4.txt',\n",
    "        'valmax5.txt',\n",
    "        'valmax6.txt',\n",
    "        'valmax7.txt',\n",
    "        'valmax8.txt',\n",
    "        'valmax9.txt',\n",
    "        'vell1.txt',\n",
    "        'vell2.txt',\n",
    "    ],\n",
    "    'late_silver': [\n",
    "    ],\n",
    "    'old': [\n",
    "        '12tables.txt',\n",
    "        'ter.adel.txt',\n",
    "        'ter.andria.txt',\n",
    "        'ter.eunuchus.txt',\n",
    "        'ter.heauton.txt',\n",
    "        'ter.hecyra.txt',\n",
    "        'ter.phormio.txt',\n",
    "        'andronicus.txt',\n",
    "        'enn.txt',\n",
    "    ],\n",
    "    'medieval': [\n",
    "        'anselmepistula.txt',\n",
    "        'anselmproslogion.txt',\n",
    "        'carm.bur.txt',\n",
    "    ],\n",
    "    'christian': [\n",
    "        'anon.martyrio.txt',\n",
    "        'benedict.txt',\n",
    "        'berengar.txt',\n",
    "        'bernardclairvaux.txt',\n",
    "        'bernardcluny.txt',\n",
    "        'bonaventura.itinerarium.txt',\n",
    "        'creeds.txt',\n",
    "        'decretum.txt',\n",
    "        'diesirae.txt',\n",
    "        'egeria.txt',\n",
    "        'ennodius.txt',\n",
    "        'eucherius.txt',\n",
    "        'eugippius.txt',\n",
    "        'greg.txt',\n",
    "        'gregory.txt',\n",
    "        'gregory7.txt',\n",
    "        'hydatius.txt',\n",
    "        'hymni.txt',\n",
    "        'innocent.txt',\n",
    "        'hydatius.txt',\n",
    "        'junillus.txt',\n",
    "        'lactantius.txt',\n",
    "        'liberpontificalis.txt',\n",
    "        'macarius.txt',\n",
    "        'macarius1.txt',\n",
    "        'novatian.txt',\n",
    "        'papal.txt',\n",
    "        'paulinus.poemata.txt',\n",
    "        'perp.txt',\n",
    "        'professio.txt',\n",
    "        'prosperus.txt',\n",
    "        'regula.txt',\n",
    "        'sedulius.txt',\n",
    "        'sulpiciusseverus.txt',\n",
    "        'vorag.txt',\n",
    "    ],\n",
    "    'renaissance': [\n",
    "        'petrarch.ep1.txt',\n",
    "        'petrarch.numa.txt',\n",
    "        'petrarch.rom.txt',\n",
    "    ],\n",
    "    'neo_latin': [\n",
    "        'spinoza.ethica1.txt',\n",
    "        'spinoza.ethica2.txt',\n",
    "        'spinoza.ethica3.txt',\n",
    "        'spinoza.ethica4.txt',\n",
    "        'spinoza.ethica5.txt'\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### The following were directories that weren't obviously divisible into periods based on the web site/file directory layout.\n",
    " \n",
    "\t./alanus',\n",
    "\t'./albertanus',\n",
    "\t'./albertofaix',\n",
    "\t'./aquinas',\n",
    "\t'./ammianus',\n",
    "\t'./arnobius',\n",
    "\t'./capellanus',\n",
    "\t'./cato',\n",
    "\t'./claudian',\n",
    "\t'./curtius',\n",
    "\t'./eutropius',\n",
    "\t'./frontinus',\n",
    "\t'./gestafrancorum',\n",
    "\t'./justinian',\n",
    "\t'./lactantius',\n",
    "\t'./martinbraga',\n",
    "\t'./mirandola',\n",
    "\t'./ottofreising',\n",
    "\t'./pauldeacon',\n",
    "\t'./sha',\n",
    "\t'./theodosius',\n",
    "\t'./voragine',\n",
    "\t'./walter',\n",
    "\t'./williamtyre',\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.corpus.readers import assemble_corpus\n",
    "reader = assemble_corpus(reader, corpus_texts_by_type.keys(), corpus_directories_by_type, corpus_texts_by_type )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs to classify: 863\n",
      "Original file list: 2,141\n",
      "Corrected file list: 1,278\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files_types = get_file_type_list(reader.fileids(), corpus_texts_by_type, corpus_directories_by_type)\n",
    "fileid_names, categories = zip(*files_types)\n",
    "\n",
    "# reader.fileids(fileid_names)\n",
    "reader._fileids = fileid_names\n",
    "\n",
    "DOCS_TO_CLASSIFY = list(set(ALL_FILE_IDS) ^ set(fileid_names))\n",
    "print(f'Docs to classify: {len(DOCS_TO_CLASSIFY):,}')\n",
    "\n",
    "\n",
    "print(f'Original file list: {len(ALL_FILE_IDS):,}')\n",
    "print(f'Corrected file list: {len(fileid_names):,}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: (1278,) e.g.: [6 1 1 ... 0 0 5]\n",
      "Label encoder classes: ['augustan' 'christian' 'early_silver' 'late_silver' 'medieval'\n",
      " 'neo_latin' 'old' 'renaissance' 'republican']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform( np.array(categories).ravel())\n",
    "print(f'Y shape: {y.shape} e.g.: {y}')\n",
    "print(f'Label encoder classes: {label_encoder.classes_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity (data):\n",
    "    \"\"\"Identity, as in math; you know, do nothing, just be yourself.\"\"\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'quick', 'brow', 'fox', 'The', 'lazy', 'dog'], ['Waiting', 'for', 'godot', 'Looking', 'for', 'the', 'sunshine']]\n"
     ]
    }
   ],
   "source": [
    "dummyX = [\n",
    "    ['The quick brown fox. The lazy dog.'],\n",
    "    ['Waiting for godot. Looking for the sunshine.']\n",
    "]\n",
    "\n",
    "newX = Doc2TokensTransformer().transform(dummyX)\n",
    "print(list(newX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = list(reader.docs(reader.fileids()))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "# With a larger labelled data set our test size would be higher, but lower here is okay\n",
    "# because we just want to see some differences among classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 1150, X_test size: 128, y_train size: 1150, y_test size: 128\n"
     ]
    }
   ],
   "source": [
    "print('X_train size: {}, X_test size: {}, y_train size: {}, y_test size: {}'.format(len(X_train),\n",
    "                                                                                    len(X_test),\n",
    "                                                                                    len(y_train),\n",
    "                                                                                    len(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6953125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('normalizer', Doc2TokensTransformer(drop_regexes=[re.compile('[0-9]+[a-zA-Z]'), re.compile('\\\\s+')],\n",
       "           language=None, valid_chars=None)), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', inp...True, vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(\"Accuracy: %s\" % classifier.score(X_test, y_test))\n",
    "    return classifier\n",
    "\n",
    "trial1 = Pipeline([\n",
    "    ('normalizer', Doc2TokensTransformer()),\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "        analyzer='word',\n",
    "        tokenizer=identity,\n",
    "        preprocessor=identity,\n",
    "        token_pattern=None)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "train(trial1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_selection(X_train, y_train, X_test, y_test, estimator):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('normalizer', Doc2TokensTransformer()),\n",
    "        ('vectorizer', TfidfVectorizer(\n",
    "            analyzer='word',\n",
    "            tokenizer=identity,\n",
    "            preprocessor=identity,\n",
    "            token_pattern=None)),\n",
    "        ('classifier', estimator())\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    return (\"Accuracy: %s\" % model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing <class 'sklearn.svm.classes.LinearSVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 1/9 [00:02<00:22,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6796875\n",
      "Testing <class 'sklearn.svm.classes.SVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 2/9 [00:05<00:19,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6796875\n",
      "Testing <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 3/9 [00:08<00:16,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6640625\n",
      "Testing <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 4/9 [00:12<00:16,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6796875\n",
      "Testing <class 'sklearn.linear_model.logistic.LogisticRegression'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 5/9 [00:15<00:12,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6953125\n",
      "Testing <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 6/9 [00:18<00:09,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46875\n",
      "Testing <class 'sklearn.ensemble.bagging.BaggingClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 7/9 [00:21<00:05,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6796875\n",
      "Testing <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 8/9 [00:23<00:02,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6796875\n",
      "Testing <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 9/9 [00:26<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LinearSVC, SVC, KNeighborsClassifier, LogisticRegressionCV,\n",
    "        LogisticRegression, SGDClassifier, BaggingClassifier,\n",
    "        ExtraTreesClassifier, RandomForestClassifier]\n",
    "\n",
    "for cls in tqdm(classifiers):\n",
    "    print(f'Testing {str(cls)}')\n",
    "    print(model_selection(X_train, y_train, X_test, y_test, cls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('normalizer', Doc2TokensTransformer(drop_regexes=[re.compile('[0-9]+[a-zA-Z]'), re.compile('\\\\s+')],\n",
       "           language=None, valid_chars=None)), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', inp...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train all the data using a reasonable winner\n",
    "model = Pipeline([\n",
    "    ('normalizer', Doc2TokensTransformer()),\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "        analyzer='word',\n",
    "        tokenizer=identity,\n",
    "        preprocessor=identity,\n",
    "        token_pattern=None)),\n",
    "    ('classifier', SGDClassifier())\n",
    "])\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape new_labels: (863,) e.g.: [1 2 0 1 2]...\n"
     ]
    }
   ],
   "source": [
    "unclassified_reader =get_corpus_reader(corpus_name='latin_text_latin_library', language='latin')\n",
    "unclassified_reader.skip_keywords = None\n",
    "to_classify_X = list(unclassified_reader.docs(DOCS_TO_CLASSIFY ))\n",
    "new_labels = model.predict(to_classify_X)\n",
    "print (f'Shape new_labels: {new_labels.shape} e.g.: {new_labels[:5]}...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'christian': ['malaterra3.txt', 'justin/27.txt', 'zonaras.txt', 'richerus1.txt', 'vegetius1.txt', 'justin/20.txt', 'sha/aurel.txt', 'gaud.txt', 'holberg.txt', 'dumdiane.txt', 'albertofaix/hist1.txt', 'gaius3.txt', 'justin/40.txt', 'williamtyre/18.txt', 'gestafrancorum/gestafrancorum6.txt', 'arnobius/arnobius6.txt', 'albertofaix/hist6.txt', 'justin/10.txt', 'thesauro.txt', 'ammianus/21.txt', 'owen.txt', 'wmconchesdogma.txt', 'sha/alexsev.txt', 'justin/23.txt', 'apuleius/apuleius.apol.txt', 'appverg.catalepton.txt', 'justin/16.txt', 'voragine/nic.txt', 'ammianus/20.txt', 'apuleius/apuleius.mundo.txt', 'gregdecretals3.txt', 'capellanus/capellanus2.txt', 'grattius.txt', 'lucernarium.txt', 'gestafrancorum/gestafrancorum7.txt', 'aus.sept.sent.txt', 'justin/15.txt', 'gestafrancorum/gestafrancorum3.txt', 'mirabilia1.txt', 'withof4.txt', 'williamtyre/1.txt', 'debury.txt', 'walter7.txt', 'walter/pastourelles.txt', 'justin/9.txt', 'williamtyre/8.txt', 'aus.mos.txt', 'albertofaix/hist11.txt', 'justin/25.txt', 'anon.nev.txt', 'withof6.txt', 'angilbert.txt', 'janus1.txt', 'aelredus.txt', 'walter11.txt', 'justin/24.txt', 'vegetius4.txt', 'williamtyre/17.txt', 'justin/praefatio.txt', 'capellanus/capellanus1.txt', 'garland.txt', 'albertofaix/hist4.txt', 'albertofaix/hist7.txt', 'albertanus/albertanus4.txt', 'andreasbergoma.txt', 'arnobius/arnobius7.txt', 'rutilius.txt', 'voragine/iul.txt', 'vegius.txt', 'waltarius1.txt', 'apuleius/apuleius.deosocratis.txt', 'capellanus/capellanus3.txt', 'rimbaud.txt', 'ammianus/31.txt', 'albertanus/albertanus.sermo4.txt', 'andecavis.txt', 'milton.quintnov.txt', 'justin/7.txt', 'appvergculex.txt', 'alanus/alanus1.txt', 'voragine/seb.txt', 'voragine/silv.txt', 'voragine/thom.txt', 'gaius1.txt', 'walter/walter1.txt', 'arnobius/arnobius1.txt', 'ammianus/23.txt', 'gestafrancorum/gestafrancorum5.txt', 'albertanus/albertanus.sermo3.txt', 'voragine/fran.txt', 'planctus.txt', 'withof2.txt', 'justin/18.txt', 'voragine/anast.txt', 'valesianus1.txt', 'arnobius/arnobius2.txt', 'walter8.txt', 'ammianus/18.txt', 'albertanus/albertanus1.txt', 'arnobius/arnobius5.txt', 'walter5.txt', 'pascoli.veianius.txt', 'justin/prologi.txt', 'waltarius3.txt', 'williamtyre/21.txt', 'justin/37.txt', 'justin/32.txt', 'gestafrancorum/gestafrancorum10.txt', 'williamtyre/9.txt', 'gravissimas.txt', 'albertanus/albertanus.liberconsol.txt', 'williamtyre/5.txt', 'wmconchesphil.txt', 'gestafrancorum/gestafrancorum1.txt', 'voragine/blas.txt', 'richerus2.txt', 'gaius2.txt', 'pontano.txt', 'arnobius/arnobius3.txt', 'albertofaix/hist8.txt', 'voragine/iacob.txt', 'ipsavivere.txt', 'smarius.txt', 'sha/geta.txt', 'richerus3.txt', 'albertofaix/hist2.txt', 'apuleius/apuleius.dog1.txt', 'ammianus/25.txt', 'albertofaix/hist3.txt', 'williamtyre/11.txt', 'appverg.aetna.txt', 'ilias.txt', 'albertanus/albertanus.sermo2.txt', 'vico.orat6.txt', 'albertanus/albertanus3.txt', 'albertofaix/hist12.txt', 'ammianus/14.txt', 'voragine/marina.txt', 'asserius.txt', 'albertanus/albertanus2.txt', 'voragine/luc.txt', 'williamtyre/22.txt', 'arnulf.txt', 'ammianus/26.txt', 'venantius.txt', 'ammianus/29.txt', 'ammianus/17.txt', 'williamtyre/6.txt', 'williamtyre/12.txt', 'sha/avid.txt', 'arnobius/arnobius4.txt', 'diravi.txt', 'valesianus.txt', 'indices.txt', 'williamtyre/3.txt', 'justin/38.txt', 'williamtyre/7.txt', 'gestafrancorum/gestafrancorum2.txt', 'declaratio.txt', 'malaterra4.txt', 'archpoet.txt', 'vitacaroli.txt', 'walter/walter3.txt', 'williamtyre/16.txt', 'williamtyre/23.txt', 'williamtyre/4.txt', 'williamtyre/15.txt', 'justin/1.txt', 'justin/3.txt', 'mapps2.txt', 'alanus/alanus2.txt', 'iordanes2.txt', 'malaterra2.txt', 'williamtyre/10.txt', 'germanicus.txt', 'justin/33.txt', 'albertofaix/hist10.txt', 'avienus.periegesis.txt', 'adso.txt', 'sha/aelii.txt', 'justin/13.txt', 'justin/17.txt', 'justin/34.txt', 'sha/ant.txt', 'justin/14.txt', 'justin/35.txt', 'voragine/andrea.txt', 'valesianus2.txt', 'abbofloracensis.txt', 'gregdecretals1.txt', 'voragine/septem.txt', 'volovirum.txt', 'ampelius.txt', 'appvergcomp.txt', 'williamtyre/20.txt', 'walter4.txt', 'vestiunt.txt', 'ammianus/19.txt', 'gaius4.txt', 'ammianus/22.txt', 'williamtyre/13.txt', 'obsequens.txt', 'justin/19.txt', 'voragine/vir.txt', 'fabe.txt', 'gestafrancorum/gestafrancorum4.txt', 'justin/12.txt', 'williamtyre/2.txt', 'voragine/alexio.txt', 'voragine/paulo.txt', 'ammianus/28.txt', 'vegetius2.txt', 'withof1.txt', 'justin/31.txt', 'voragine/jud.txt', 'johannes.txt', 'walter9.txt', 'voragine/georgio.txt', 'justin/8.txt', 'williamtyre/19.txt', 'gauss.txt', 'walter10.txt', 'williamtyre/14.txt', 'williamapulia.txt', 'vicentius.txt', 'epitaphs.txt', 'walter/walter2.txt', 'ruaeus.txt', 'ammianus/15.txt', 'godfrey.epigrammatahist.txt', 'justin/21.txt', 'albertanus/albertanus.arsloquendi.txt', 'albertanus/albertanus.sermo.txt', 'justin/2.txt', 'justin/6.txt', 'justin/42.txt', 'gregdecretals5.txt', 'ammianus/16.txt', 'vegetius3.txt', 'voragine/ant.txt', 'voragine/marc.txt', 'voragine/ambro.txt', 'asconius.txt', 'paris.txt', 'annalesvedastini.txt', 'justin/39.txt', 'justin/22.txt', 'withof.txt', 'justin/26.txt', 'waltarius2.txt', 'iamdulcis.txt', 'withof7.txt', 'justin/28.txt', 'ammianus/30.txt', 'pascoli.iug.txt', 'ammianus/24.txt', 'justin/43.txt', 'justin/41.txt', 'walter6.txt', 'albertofaix/hist9.txt', 'justin/4.txt', 'appverg.ciris.txt', 'walter12.txt', 'annalesregnifrancorum.txt', 'gioacchino.txt', 'withof3.txt', 'voragine/chris.txt', 'raoul.txt', 'letabundus.txt', 'malaterra1.txt', 'justin/30.txt', 'inscriptions.txt', 'iordanes1.txt', 'fortunat.txt', 'richerus4.txt', 'passerat.txt', 'marx.txt', 'gestafrancorum/gestafrancorum8.txt', 'justin/11.txt', 'vida.txt', 'albertanus/albertanus.sermo1.txt', 'gregdecretals2.txt', 'justin/44.txt', 'gestafrancorum/gestafrancorum9.txt', 'williamtyre/prologus.txt', 'gregdecretals4.txt', 'inquisitio.txt', 'justin/29.txt', 'justin/36.txt', 'janus2.txt', 'justin/5.txt', 'reposianus.txt', 'godfrey.epigrammata.txt', 'tunger.txt', 'avienus.ora.txt', 'albertofaix/hist5.txt', 'avianus.txt', 'xanten.txt', 'ammianus/27.txt', 'mapps1.txt', 'withof5.txt', 'voragine/vin.txt', 'gestarom.txt', 'garcilaso.txt', 'apuleius/apuleius.dog2.txt'], 'early_silver': ['aquinas/q1.74.txt', 'sidonius6.txt', 'aquinas/q1.36.txt', 'theodosius/theod08.txt', 'aquinas/q1.23.txt', 'claud.inscr.txt', 'sedulius5.txt', 'solinus2a.txt', 'calpurniussiculus.txt', 'sha/30.txt', 'aquinas/q1.24.txt', 'aquinas/q1.50.txt', 'aquinas/q1.61.txt', 'prosperus.epistola.txt', 'sedulius4.txt', 'pascoli.sen.txt', 'aquinas/q1.31.txt', 'sidonius5.txt', 'aquinas/q1.55.txt', 'aquinas/q1.2.txt', 'aquinas/q1.47.txt', 'aquinas/q1.46.txt', 'aquinas/q1.67.txt', 'sulpiciusseveruschron2.txt', 'aquinas/prologus.txt', 'aquinas/epist.txt', 'aquinas/q1.25.txt', 'aquinas/q1.30.txt', 'aquinas/q1.65.txt', 'aquinas/q1.49.txt', 'sidonius2.txt', 'theodosius/theod05.txt', 'theodosius/theod10.txt', 'theodosius/theod15.txt', 'theodosius/theod07.txt', 'sulpiciusseverusmartin.txt', 'aquinas/q1.80.txt', 'aquinas/q1.8.txt', 'aquinas/q1.7.txt', 'landor1806.txt', 'aquinas/q1.54.txt', 'theodosius/theod13.txt', 'solinus4.txt', 'sidonius3.txt', 'aquinas/q1.41.txt', 'aquinas/q1.56.txt', 'sidonius4.txt', 'aquinas/q1.57.txt', 'aquinas/q1.51.txt', 'justinian/institutes1.txt', 'aquinas/q1.40.txt', 'theodolus.txt', 'sedulius.solis.txt', 'sedulius3.txt', 'aquinas/q1.83.txt', 'sha/gall.txt', 'sigebert.virgin.txt', 'aquinas/q1.42.txt', 'aquinas/q1.48.txt', 'aquinas/q1.37.txt', 'aquinas/q1.71.txt', 'solinus3a.txt', 'aquinas/q1.45.txt', 'aquinas/q1.19.txt', 'solinus1a.txt', 'aquinas/princ.txt', 'aquinas/q1.21.txt', 'aquinas/q1.81.txt', 'aquinas/q1.20.txt', 'aquinas/q1.34.txt', 'aquinas/q1.35.txt', 'sabinus1.txt', 'solinus1.txt', 'sidonius7.txt', 'aquinas/q1.39.txt', 'theodosius/theod16.txt', 'justinian/institutes.proem.txt', 'aquinas/q1.5.txt', 'aquinas/q1.14.txt', 'theophanes.txt', 'aquinas/q1.1.txt', 'theodosius/theod01.txt', 'aquinas/q1.44.txt', 'theodosius/theod02.txt', 'quum.txt', 'septsap.txt', 'theodosius/theod06.txt', 'aquinas/q1.38.txt', 'fulbert.txt', 'aquinas/q1.60.txt', 'solet.txt', 'aquinas/q1.69.txt', 'thomasedessa.txt', 'aquinas/q1.15.txt', 'simedignetur.txt', 'scottus.txt', 'sabinus2.txt', 'scaliger.txt', 'aquinas/q1.43.txt', 'aquinas/q1.62.txt', 'aquinas/q1.26.txt', 'aquinas/q1.17.txt', 'sedulius1.txt', 'tempusest.txt', 'justinian/institutes4.txt', 'aquinas/q1.59.txt', 'suscipeflos.txt', 'more.txt', 'aquinas/q1.13.txt', 'aquinas/q1.6.txt', 'sha/tacitus.txt', 'sedulius2.txt', 'aquinas/p1.txt', 'aquinas/q1.11.txt', 'justinian/institutes2.txt', 'aquinas/q1.82.txt', 'aquinas/q1.32.txt', 'sidonius8.txt', 'aquinas/q1.58.txt', 'aquinas/q1.28.txt', 'sidonius1.txt', 'solinus5.txt', 'aquinas/q1.22.txt', 'theodosius/theod03.txt', 'aquinas/q1.33.txt', 'aquinas/q1.10.txt', 'aquinas/ente.txt', 'terraiam.txt', 'aquinas/q1.53.txt', 'sigebert.vitabrevior.txt', 'sha/val.txt', 'aquinas/corpuschristi.txt', 'prosperus.rufinum.txt', 'aquinas/q1.64.txt', 'prop4.txt', 'sha/sepsev.txt', 'aquinas/q1.27.txt', 'solinus4a.txt', 'solinus2.txt', 'prosperus.sententiae.txt', 'aquinas/q1.18.txt', 'aquinas/q1.52.txt', 'scbaccanalibus.txt', 'sannazaro2.txt', 'theodosius/theod04.txt', 'theodosius/theod09.txt', 'sicmeafata.txt', 'aquinas/q1.4.txt', 'testamentum.txt', 'theganus.txt', 'sidonius9.txt', 'aquinas/q1.73.txt', 'theodosius/theod14.txt', 'sabinus3.txt', 'aquinas/expositio.txt', 'sannazaro1.txt', 'aquinas/q1.63.txt', 'theodosius/theod12.txt', 'aquinas/q1.70.txt', 'sulpiciusseveruschron1.txt', 'aquinas/q1.16.txt', 'aquinas/q1.87.txt', 'aquinas/q1.3.txt', 'theodosius/theod11.txt', 'sha/firmus.txt', 'solinus3.txt', 'aquinas/q1.12.txt', 'sha/gord.txt', 'aquinas/q1.66.txt', 'landor1795.txt', 'index.txt', 'aquinas/q1.72.txt', 'aquinas/q1.9.txt', 'sigebert.script.txt', 'aquinas/q1.86.txt', 'aquinas/q1.68.txt', 'justinian/institutes3.txt', 'aquinas/q1.29.txt'], 'augustan': ['hipp.txt', 'piccolomini.ep6.txt', 'lactantius/divinst1.txt', 'pauldeacon/hist1.txt', 'pauldeacon/carmina.txt', 'pauldeacon/hist6.txt', 'pomponius1.txt', 'rutiliuslupus.txt', 'histbrit.txt', 'forsett1.txt', 'psplato.halcyon.txt', 'ebulo.txt', 'henrysettimello.txt', 'pulchracomis.txt', 'axio.txt', 'voragine/mariamag.txt', 'clitophon.txt', 'kalila.txt', 'pauldeacon/histrom12.txt', 'poggio.txt', 'pauldeacon/histrom4.txt', 'fletcher.txt', 'piccolomini.ep1.txt', 'innocent1.txt', 'prop3.txt', 'prataiam.txt', 'lotichius.txt', 'pauldeacon/histrom16.txt', 'pauldeacon/fabulae.txt', 'sha/hadr.txt', 'sha/probus.txt', 'luther.95.txt', 'caeciliusbalbus.txt', 'iabervocius.txt', 'potatores.txt', 'pascoli.laur.txt', 'pervig.txt', 'pauldeacon/histrom8.txt', 'pauldeacon/histrom6.txt', 'leo3.txt', 'pauldeacon/histrom11.txt', 'oresmius.txt', 'falcandus.txt', 'origo.txt', 'pauldeacon/hist3.txt', 'porphyrius.txt', 'paulinus.ausonium.txt', 'ottofreising/epistola.txt', 'pauldeacon/histrom10.txt', 'pauldeacon/histrom14.txt', 'comes.txt', 'pomponius2.txt', 'pauldeacon/histrom15.txt', 'pauldeacon/histrom3.txt', 'cinna.txt', 'psplato.iusto.txt', 'priapea.txt', 'protospatarius.txt', 'psplato.sisyphus.txt', 'lactantius/demort.txt', 'lhomond.historiae.txt', 'piccolomini.ep3.txt', 'ottofreising/3.txt', 'luther.lteramus.txt', 'hydatiusfasti.txt', 'ottofreising/4.txt', 'precatio.txt', 'piccolomini.turcos.txt', 'piccolomini.ep5.txt', 'sha/pesc.txt', 'forsett2.txt', 'pauldeacon/hist4.txt', 'pauldeacon/histrom7.txt', 'corvinus2.txt', 'psplato.amatores.txt', 'psplato.demodocus.txt', 'cato/cato.frag.txt', 'ottofreising/2.txt', 'prop2.txt', 'prec.terr.txt', 'pauldeacon/histrom9.txt', 'ave.phoen.txt', 'alfonsi.disciplina.txt', 'piccolomini.ep2.txt', 'mirandola/oratio.txt', 'oratio.stephani.txt', 'omnegenus.txt', 'leo2.txt', 'sha/verus.txt', 'psplato.eryxias.txt', 'sha/pert.txt', 'pauldeacon/hist2.txt', 'victor.caes.txt', 'piccolomini.ep4.txt', 'ottofreising/1.txt', 'corvinus1.txt', 'hydatiuschronicon.txt', 'jfkhonor.txt', 'leo1.txt', 'columba1.txt', 'cotta.txt', 'pomponius3.txt', 'columba2.txt', 'luther.praef.txt', 'liberpontificalis1.txt', 'pauldeacon/histrom2.txt', 'syrus.txt', 'blesensis.txt', 'pauldeacon/histrom1.txt', 'pauldeacon/histrom13.txt', 'psplato.minos.txt', 'histapoll.txt', 'petrarchmedicus.txt', 'hrabanus.txt', 'legenda.stephani.txt', 'pauldeacon/hist5.txt', 'pauldeacon/histrom5.txt', 'hebet.txt', 'landor1810.txt', 'lhomond.viris.txt', 'innocent2.txt', 'psplato.virtu.txt'], 'late_silver': ['patricius1.txt', 'patricius2.txt', 'frontinus/mensoria.txt', 'frontinus/qualitate.txt', 'frontinus/strat1.txt', 'florus2.txt', 'ency.fides.txt', 'apuleius/apuleius.florida.txt', 'frodebertus.txt', 'montanus.txt', 'fragmentumlaurentianum.txt', 'frontinus/lim.txt', 'florus1.txt', 'fredegarius.txt', 'frontinus/strat3.txt', 'frontinus/contro.txt', 'frontinus/strat2.txt', 'frontinus/aqua1.txt', 'frontinus/strat4.txt', 'frontinus/aqua2.txt'], 'neo_latin': ['dulcesolum.txt', 'minucius.txt', 'justinian/digest35.txt', 'halley.txt', 'magnacarta.txt', 'martinbraga/ira.txt', 'justinian/digest30.txt', 'eutropius/eutropius6.txt', 'martinbraga/poems.txt', 'justinian/digest36.txt', 'eutropius/eutropius1.txt', 'epitomecononiana.txt', 'justinian/digest7.txt', 'bernardcluny1.txt', 'piccolomini.carmen.txt', 'justinian/digest3.txt', 'epitomefeliciana.txt', 'levis.txt', 'don.txt', 'apuleius/apuleius6.txt', 'dumdomus.txt', 'biggs.txt', 'eutropius/eutropius5.txt', 'justinian/digest41.txt', 'exivi.txt', 'justinian/digest50.txt', 'sha/marcant.txt', 'justinian/digest6.txt', 'walton.txt', 'dicchristi.txt', 'dares.txt', 'justinian/digest13.txt', 'apuleius/apuleius3.txt', 'martinbraga/concilium2.txt', 'justinian/digest18.txt', 'justinian/digest1.txt', 'eutropius/eutropius7.txt', 'ein.txt', 'justinian/digest39.txt', 'mirabilia.txt', 'justinian/digest33.txt', 'justinian/digest19.txt', 'justinian/digest27.txt', 'martinbraga/sententiae.txt', 'tevigilans.txt', 'martinbraga/capitula.txt', 'sha/max.txt', 'eutropius/eutropius9.txt', 'buchanan.txt', 'justinian/digest11.txt', 'epistaustras.txt', 'egeria2.txt', 'martinbraga/trina.txt', 'sha/maxbal.txt', 'rhetores.txt', 'foedusaeternum.txt', 'landor.1858.txt', 'apuleius/apuleius7.txt', 'dares1.txt', 'justinian/digest44.txt', 'arbroath.txt', 'martinbraga/rusticus.txt', 'marcellinus2.txt', 'eutropius/eutropius4.txt', 'martinbraga/superbia.txt', 'rumor.txt', 'sha/mac.txt', 'justinian/digest31.txt', 'justinian/digest24.txt', 'dumestas.txt', 'martinbraga/exhortatio.txt', 'apuleius/apuleius10.txt', 'brevechronicon.txt', 'ep.priapismo.txt', 'justinian/digest43.txt', 'victor.origio.txt', 'eutropius/eutropius3.txt', 'justinian/digest23.txt', 'justinian/digest25.txt', 'justinian/digest46.txt', 'justinian/digest34.txt', 'balbus.txt', 'justinian/digest16.txt', 'baldo.txt', 'victor.ill.txt', 'apuleius/apuleius5.txt', 'justinian/digest20.txt', 'justinian/digest40.txt', 'eutropius/eutropius2.txt', 'justinian/digest21.txt', 'balde1.txt', 'justinian/digest17.txt', 'apuleius/apuleius8.txt', 'justinian/digest29.txt', 'bill.rights.txt', 'justinian/digest12.txt', 'bernardcluny2.txt', 'justinian/digest26.txt', 'maximianus.txt', 'sha/helio.txt', 'justinian/digest14.txt', 'eugenius.txt', 'justinian/digest4.txt', 'justinian/digest32.txt', 'justinian/digest42.txt', 'maidstone.txt', 'sha/diad.txt', 'cato.dis.txt', 'justinian/digest10.txt', 'boskovic.txt', 'justinian/digest38.txt', 'martinbraga/formula.txt', 'fronto.txt', 'justinian/digest22.txt', 'apuleius/apuleius9.txt', 'justinian/digest47.txt', 'justinian/digest8.txt', 'justinian/digest5.txt', 'erchempert.txt', 'eutropius/eutropius10.txt', 'marbodus.txt', 'ficino.txt', 'justinian/digest48.txt', 'marullo.txt', 'apuleius/apuleius1.txt', 'justinian/digest9.txt', 'donation.txt', 'martinbraga/concilium1.txt', 'justinian/digest37.txt', 'agnes.txt', 'apuleius/apuleius2.txt', 'balde2.txt', 'bebel.txt', 'martinbraga/repellenda.txt', 'musavenit.txt', 'justinian/digest49.txt', 'martinbraga/pascha.txt', 'dicquid.txt', 'estas.txt', 'cato/cato.agri.txt', 'justinian/digest2.txt', 'marcellinus1.txt', 'victor.caes2.txt', 'justinian/digest15.txt', 'apuleius/apuleius4.txt', 'sha/didiul.txt', 'justinian/digest28.txt', 'justinian/digest45.txt', 'egeria1.txt', 'eutropius/eutropius8.txt', 'apuleius/apuleius11.txt'], 'republican': ['claudian/claudian.proserp2.txt', 'nemesianus1.txt', 'gwinne5.4.txt', 'nithardus3.txt', 'catalogueliberien.txt', 'claudian/claudian.olyb.txt', 'justinian/codex4.txt', 'justinian/codex12.txt', 'justinian/codex1.txt', 'apuleius/apuleius.cupid.txt', 'mirandola/mir8.txt', 'justinian/codex7.txt', 'henry1.txt', 'justinian/codex10.txt', 'justinian/codex2.txt', 'nithardus4.txt', 'newton.scholium.txt', 'ferraria.txt', 'waardenburg.txt', 'celtis.odes.txt', 'sha/claud.txt', 'nemesianus3.txt', 'anon.deramis.txt', 'calpurniusflaccus.txt', 'pascoli.catull.txt', 'claudian/claudian.proserp3.txt', 'mirandola/mir5.txt', 'nobilis.txt', 'gwinne5.3.txt', 'censorinus.txt', 'justinian/codex6.txt', 'gwinne2.txt', 'henry2.txt', 'mirandola/mir2.txt', 'newton.capita.txt', 'justinian/codex5.txt', 'sha/car.txt', 'newton.regulae.txt', 'notitia1.txt', 'notitia2.txt', 'nithardus2.txt', 'sha/com.txt', 'gwinne5.2.txt', 'celtis.oratio.txt', 'gwinne4.txt', 'curtius/curtius3.txt', 'colman.txt', 'justinian/codex8.txt', 'gwinne5.1.txt', 'curtius/curtius5.txt', 'falcone.txt', 'mirandola/mir3.txt', 'carmenarvale.txt', 'curtius/curtius4.txt', 'mirandola/mir4.txt', 'columbus.txt', 'mirandola/mir6.txt', 'carmeninvictoriam.txt', 'curtius/curtius10.txt', '1644.txt', 'claudian/claudian.ruf1.txt', 'justinian/codex3.txt', 'nivis.txt', 'curtius/curtius8.txt', 'gwinne3.txt', 'curtius/curtius9.txt', 'justinian/codex11.txt', 'sha/carus.txt', 'mirandola/mir9.txt', 'nithardus1.txt', 'sha/clod.txt', 'poree.txt', 'mirandola/mir1.txt', 'curtius/curtius7.txt', 'henry3.txt', 'curtius/curtius6.txt', 'gwinne1.txt', 'navagero.txt', 'nemesianus2.txt', 'newton.leges.txt', 'nemesianus4.txt', 'naevius.txt', 'mirandola/mir7.txt', 'claudian/claudian.cons6.txt', 'justinian/codex9.txt', 'claudian/claudian.proserp1.txt', 'carmensaliare.txt']})\n"
     ]
    }
   ],
   "source": [
    "new_cats = defaultdict(list)\n",
    "for idx, filename in enumerate(DOCS_TO_CLASSIFY):\n",
    "    new_cats[label_encoder.classes_[new_labels[idx]]].append(filename)\n",
    "print(new_cats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_cats.json', mode='w', encoding='utf8') as writer:\n",
    "    json.dump(new_cats, writer, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('latin_text_classifier.mdl.pkl', 'wb') as writer:\n",
    "    joblib.dump(new_cats, writer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vetting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the corrected labellings\n",
    "from cltk.corpus.latin.latin_library_corpus_types import corpus_directories_by_type as new_corpus_type_dirs \n",
    "from cltk.corpus.latin.latin_library_corpus_types import corpus_texts_by_type as new_corpus_text_types\n",
    "# diff the old and new\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
