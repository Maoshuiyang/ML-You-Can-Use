{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from cltk.corpus.readers import FilteredPlaintextCorpusReader\n",
    "from cltk.corpus.readers import  get_corpus_reader\n",
    "from cltk.corpus.latin.latin_library_corpus_types import  corpus_directories_by_type, corpus_texts_by_type  \n",
    "\n",
    "from cltk.prosody.latin.string_utils import punctuation_for_spaces_dict\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "from cltk.tokenize.sentence import TokenizeSentence\n",
    "from cltk.prosody.latin.scansion_constants import ScansionConstants\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing.label import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "\n",
    "\n",
    "from doc2tokens_transformer import Doc2TokensTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12tables.txt', '1644.txt', 'abbofloracensis.txt', 'abelard/dialogus.txt', 'abelard/epistola.txt']\n"
     ]
    }
   ],
   "source": [
    "reader =get_corpus_reader('latin_text_latin_library')\n",
    "#root, FILEIDS, word_tokenizer=word_tokenizer, sent_tokenizer=sent_tokenizer)\n",
    "\n",
    "ALL_FILE_IDS = list(reader.fileids() )\n",
    "\n",
    "print(ALL_FILE_IDS[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opo Dunstano, vere moribus et aetate maturo, Abbo Floriacensis monachus levita, etsi indignus, a Chr\n"
     ]
    }
   ],
   "source": [
    "print(list(reader.docs(ALL_FILE_IDS[2]))[0][200:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label some data, but not all\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus_directories_by_type = {\n",
    "\n",
    "    'republican': [\n",
    "        './caesar',\n",
    "        './lucretius',\n",
    "        './nepos',\n",
    "        './cicero'\n",
    "    ],\n",
    "    'augustan': [\n",
    "        './livy',\n",
    "        './ovid',\n",
    "        './horace',\n",
    "        './vergil',\n",
    "        './hyginus',\n",
    "    ],\n",
    "    'early_silver': [\n",
    "        './martial',\n",
    "        './juvenal',\n",
    "        './tacitus',\n",
    "        './lucan',\n",
    "        './quintilian',\n",
    "        './sen',\n",
    "        './statius',\n",
    "        './silius',\n",
    "        './columella'\n",
    "    ],\n",
    "    'late_silver': [\n",
    "        './suetonius',\n",
    "        './gellius',\n",
    "        './apuleius'\n",
    "        './justin',\n",
    "        './apicius',\n",
    "        './fulgentius',\n",
    "        './orosius',\n",
    "    ],\n",
    "    'old': [\n",
    "        './plautus'\n",
    "    ],\n",
    "    'christian': [\n",
    "        './ambrose',\n",
    "        './abelard',\n",
    "        './alcuin',\n",
    "        './augustine',\n",
    "        './bede',\n",
    "        './bible',\n",
    "        './cassiodorus',\n",
    "        './commodianus',\n",
    "        './gregorytours',\n",
    "        './hugo',\n",
    "        './isidore',\n",
    "        './jerome',\n",
    "        './prudentius',\n",
    "        './tertullian',\n",
    "        './kempis',\n",
    "        './leothegreat',\n",
    "    ],\n",
    "    'medieval': [\n",
    "        './boethiusdacia',\n",
    "        './dante',\n",
    "    ],\n",
    "    'renaissance': [\n",
    "    ],\n",
    "    'neo_latin': [\n",
    "        './addison',\n",
    "        './bacon',\n",
    "        './bultelius',\n",
    "        './descartes',\n",
    "        './erasmus',\n",
    "        './galileo',\n",
    "        './kepler',\n",
    "        './may',\n",
    "        './melanchthon',\n",
    "        './xylander',\n",
    "        './campion',\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "#### by text\n",
    "\n",
    "\n",
    "corpus_texts_by_type = {\n",
    "    'republican': [\n",
    "        'sall.1.txt',\n",
    "        'sall.2.txt',\n",
    "        'sall.cotta.txt',\n",
    "        'sall.ep1.txt',\n",
    "        'sall.ep2.txt',\n",
    "        'sall.frag.txt',\n",
    "        'sall.invectiva.txt',\n",
    "        'sall.lep.txt',\n",
    "        'sall.macer.txt',\n",
    "        'sall.mithr.txt',\n",
    "        'sall.phil.txt',\n",
    "        'sall.pomp.txt',\n",
    "        'varro.frag.txt',\n",
    "        'varro.ll10.txt',\n",
    "        'varro.ll5.txt',\n",
    "        'varro.ll6.txt',\n",
    "        'varro.ll7.txt',\n",
    "        'varro.ll8.txt',\n",
    "        'varro.ll9.txt',\n",
    "        'varro.rr1.txt',\n",
    "        'varro.rr2.txt',\n",
    "        'varro.rr3.txt',\n",
    "        'sulpicia.txt',\n",
    "    ],\n",
    "    'augustan': [\n",
    "        'resgestae.txt',\n",
    "        'resgestae1.txt',\n",
    "        'manilius1.txt',\n",
    "        'manilius2.txt',\n",
    "        'manilius3.txt',\n",
    "        'manilius4.txt',\n",
    "        'manilius5.txt',\n",
    "        'catullus.txt',\n",
    "        'vitruvius1.txt',\n",
    "        'vitruvius10.txt',\n",
    "        'vitruvius2.txt',\n",
    "        'vitruvius3.txt',\n",
    "        'vitruvius4.txt',\n",
    "        'vitruvius5.txt',\n",
    "        'vitruvius6.txt',\n",
    "        'vitruvius7.txt',\n",
    "        'vitruvius8.txt',\n",
    "        'vitruvius9.txt',\n",
    "        'propertius1.txt',\n",
    "        'tibullus1.txt',\n",
    "        'tibullus2.txt',\n",
    "        'tibullus3.txt',\n",
    "    ],\n",
    "    'early_silver': [\n",
    "        'pliny.ep1.txt',\n",
    "        'pliny.ep10.txt',\n",
    "        'pliny.ep2.txt',\n",
    "        'pliny.ep3.txt',\n",
    "        'pliny.ep4.txt',\n",
    "        'pliny.ep5.txt',\n",
    "        'pliny.ep6.txt',\n",
    "        'pliny.ep7.txt',\n",
    "        'pliny.ep8.txt',\n",
    "        'pliny.ep9.txt',\n",
    "        'pliny.nh1.txt',\n",
    "        'pliny.nh2.txt',\n",
    "        'pliny.nh3.txt',\n",
    "        'pliny.nh4.txt',\n",
    "        'pliny.nh5.txt',\n",
    "        'pliny.nhpr.txt',\n",
    "        'pliny.panegyricus.txt',\n",
    "        'petronius1.txt',\n",
    "        'petroniusfrag.txt',\n",
    "        'persius.txt',\n",
    "        'phaedr1.txt',\n",
    "        'phaedr2.txt',\n",
    "        'phaedr3.txt',\n",
    "        'phaedr4.txt',\n",
    "        'phaedr5.txt',\n",
    "        'phaedrapp.txt',\n",
    "        'seneca.contr1.txt',\n",
    "        'seneca.contr10.txt',\n",
    "        'seneca.contr2.txt',\n",
    "        'seneca.contr3.txt',\n",
    "        'seneca.contr4.txt',\n",
    "        'seneca.contr5.txt',\n",
    "        'seneca.contr6.txt',\n",
    "        'seneca.contr7.txt',\n",
    "        'seneca.contr8.txt',\n",
    "        'seneca.contr9.txt',\n",
    "        'seneca.fragmenta.txt',\n",
    "        'seneca.suasoriae.txt',\n",
    "        'valeriusflaccus1.txt',\n",
    "        'valeriusflaccus2.txt',\n",
    "        'valeriusflaccus3.txt',\n",
    "        'valeriusflaccus4.txt',\n",
    "        'valeriusflaccus5.txt',\n",
    "        'valeriusflaccus6.txt',\n",
    "        'valeriusflaccus7.txt',\n",
    "        'valeriusflaccus8.txt',\n",
    "        'valmax1.txt',\n",
    "        'valmax2.txt',\n",
    "        'valmax3.txt',\n",
    "        'valmax4.txt',\n",
    "        'valmax5.txt',\n",
    "        'valmax6.txt',\n",
    "        'valmax7.txt',\n",
    "        'valmax8.txt',\n",
    "        'valmax9.txt',\n",
    "        'vell1.txt',\n",
    "        'vell2.txt',\n",
    "    ],\n",
    "    'late_silver': [\n",
    "    ],\n",
    "    'old': [\n",
    "        '12tables.txt',\n",
    "        'ter.adel.txt',\n",
    "        'ter.andria.txt',\n",
    "        'ter.eunuchus.txt',\n",
    "        'ter.heauton.txt',\n",
    "        'ter.hecyra.txt',\n",
    "        'ter.phormio.txt',\n",
    "        'andronicus.txt',\n",
    "        'enn.txt',\n",
    "    ],\n",
    "    'medieval': [\n",
    "        'anselmepistula.txt',\n",
    "        'anselmproslogion.txt',\n",
    "        'carm.bur.txt',\n",
    "    ],\n",
    "    'christian': [\n",
    "        'anon.martyrio.txt',\n",
    "        'benedict.txt',\n",
    "        'berengar.txt',\n",
    "        'bernardclairvaux.txt',\n",
    "        'bernardcluny.txt',\n",
    "        'bonaventura.itinerarium.txt',\n",
    "        'creeds.txt',\n",
    "        'decretum.txt',\n",
    "        'diesirae.txt',\n",
    "        'egeria.txt',\n",
    "        'ennodius.txt',\n",
    "        'eucherius.txt',\n",
    "        'eugippius.txt',\n",
    "        'greg.txt',\n",
    "        'gregory.txt',\n",
    "        'gregory7.txt',\n",
    "        'hydatius.txt',\n",
    "        'hymni.txt',\n",
    "        'innocent.txt',\n",
    "        'hydatius.txt',\n",
    "        'junillus.txt',\n",
    "        'lactantius.txt',\n",
    "        'liberpontificalis.txt',\n",
    "        'macarius.txt',\n",
    "        'macarius1.txt',\n",
    "        'novatian.txt',\n",
    "        'papal.txt',\n",
    "        'paulinus.poemata.txt',\n",
    "        'perp.txt',\n",
    "        'professio.txt',\n",
    "        'prosperus.txt',\n",
    "        'regula.txt',\n",
    "        'sedulius.txt',\n",
    "        'sulpiciusseverus.txt',\n",
    "        'vorag.txt',\n",
    "    ],\n",
    "    'renaissance': [\n",
    "        'petrarch.ep1.txt',\n",
    "        'petrarch.numa.txt',\n",
    "        'petrarch.rom.txt',\n",
    "    ],\n",
    "    'neo_latin': [\n",
    "        'spinoza.ethica1.txt',\n",
    "        'spinoza.ethica2.txt',\n",
    "        'spinoza.ethica3.txt',\n",
    "        'spinoza.ethica4.txt',\n",
    "        'spinoza.ethica5.txt'\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### The following were directories that weren't obviously divisible into periods based on the web site/file directory layout.\n",
    " \n",
    "\t./alanus',\n",
    "\t'./albertanus',\n",
    "\t'./albertofaix',\n",
    "\t'./aquinas',\n",
    "\t'./ammianus',\n",
    "\t'./arnobius',\n",
    "\t'./capellanus',\n",
    "\t'./cato',\n",
    "\t'./claudian',\n",
    "\t'./curtius',\n",
    "\t'./eutropius',\n",
    "\t'./frontinus',\n",
    "\t'./gestafrancorum',\n",
    "\t'./justinian',\n",
    "\t'./lactantius',\n",
    "\t'./martinbraga',\n",
    "\t'./mirandola',\n",
    "\t'./ottofreising',\n",
    "\t'./pauldeacon',\n",
    "\t'./sha',\n",
    "\t'./theodosius',\n",
    "\t'./voragine',\n",
    "\t'./walter',\n",
    "\t'./williamtyre',\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original file list: 2141 \nCorrected file list: 1278\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "CLEAN_IDS_TYPES = []\n",
    "\n",
    "for key, valuelist in corpus_texts_by_type.items():\n",
    "    for value in valuelist:\n",
    "        if value in ALL_FILE_IDS:\n",
    "            CLEAN_IDS_TYPES.append((value, key))\n",
    "\n",
    "for key, valuelist in corpus_directories_by_type.items():\n",
    "    for value in valuelist:\n",
    "        corrected_dir = value.replace('./', '')\n",
    "        corrected_dir = '{}/'.format(corrected_dir)\n",
    "        for name in ALL_FILE_IDS:\n",
    "            if name.startswith(corrected_dir):\n",
    "                CLEAN_IDS_TYPES.append((name, key))\n",
    "\n",
    "CLEAN_IDS_TYPES.sort(key=lambda x: x[0])\n",
    "fileid_names, categories = zip(*CLEAN_IDS_TYPES)\n",
    "\n",
    "reader._fileids = fileid_names\n",
    "\n",
    "print('Original file list: %s ' % len(ALL_FILE_IDS))\n",
    "print('Corrected file list: %s' % len(fileid_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs to classify: 863 \n"
     ]
    }
   ],
   "source": [
    "DOCS_TO_CLASSIFY = list(set(ALL_FILE_IDS) ^ set(fileid_names))\n",
    "print('Docs to classify: %s ' % len(DOCS_TO_CLASSIFY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 1 1 ... 0 0 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform( np.array(categories).ravel())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['augustan' 'christian' 'early_silver' 'late_silver' 'medieval'\n 'neo_latin' 'old' 'renaissance' 'republican']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity (data):\n",
    "    \"\"\"Identity, as in math; you know, do nothing, just be yourself.\"\"\"\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'quick', 'brow', 'fox', 'The', 'lazy', 'dog'], ['Waiting', 'for', 'godot', 'Looking', 'for', 'the', 'sunshine']]\n"
     ]
    }
   ],
   "source": [
    "dummyX = [\n",
    "    ['The quick brown fox. The lazy dog.'],\n",
    "    ['Waiting for godot. Looking for the sunshine.']\n",
    "]\n",
    "\n",
    "newX = Doc2TokensTransformer().transform(dummyX)\n",
    "print(list(newX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = list(reader.docs(reader.fileids()))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "# With a larger labelled data set our test size would be higher, but lower here is okay\n",
    "# because we just want to see some differences among classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856\n422\n856\n422\n"
     ]
    }
   ],
   "source": [
    "print('X_train size: {}, X_test size: {}, y_train size: {}, y_test size: {}'.format(len(X_train),\n",
    "                                                                                    len(X_test),\n",
    "                                                                                    len(y_train),\n",
    "                                                                                    len(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7109004739336493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n     steps=[('normalizer', TextNormalizer(language=None, valid_chars=None)), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n      ...True, vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(\"Accuracy: %s\" % classifier.score(X_test, y_test))\n",
    "    return classifier\n",
    "\n",
    "trial1 = Pipeline([\n",
    "    ('normalizer', Doc2TokensTransformer()),\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "        analyzer='word',\n",
    "        tokenizer=identity,\n",
    "        preprocessor=identity,\n",
    "        token_pattern=None)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "train(trial1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(X_train, y_train, X_test, y_test, estimator):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('normalizer', Doc2TokensTransformer()),\n",
    "        ('vectorizer', TfidfVectorizer(\n",
    "            analyzer='word',\n",
    "            tokenizer=identity,\n",
    "            preprocessor=identity,\n",
    "            token_pattern=None)),\n",
    "        ('classifier', estimator())\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    return (\"Accuracy: %s\" % model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing <class 'sklearn.svm.classes.LinearSVC'> 2018-08-31 23:37:25.833036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7109004739336493\ntesting <class 'sklearn.svm.classes.SVC'> 2018-09-01 00:00:07.021422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6824644549763034\ntesting <class 'sklearn.neighbors.classification.KNeighborsClassifier'> 2018-09-01 00:22:11.119004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5924170616113744\ntesting <class 'sklearn.linear_model.logistic.LogisticRegressionCV'> 2018-09-01 00:43:54.351014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/todd/PycharmProjects/p36cltk/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7061611374407583\ntesting <class 'sklearn.linear_model.logistic.LogisticRegression'> 2018-09-01 01:05:26.698582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7109004739336493\ntesting <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> 2018-09-01 01:26:56.212475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/todd/PycharmProjects/p36cltk/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7014218009478673\ntesting <class 'sklearn.ensemble.bagging.BaggingClassifier'> 2018-09-01 01:48:23.356373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7061611374407583\ntesting <class 'sklearn.ensemble.forest.ExtraTreesClassifier'> 2018-09-01 02:10:04.528566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7109004739336493\ntesting <class 'sklearn.ensemble.forest.RandomForestClassifier'> 2018-09-01 02:31:35.841899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7061611374407583\ndone 2018-09-01 02:53:18.508641\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LinearSVC, SVC, KNeighborsClassifier, LogisticRegressionCV,\n",
    "        LogisticRegression, SGDClassifier, BaggingClassifier,\n",
    "        ExtraTreesClassifier, RandomForestClassifier]\n",
    "\n",
    "for cls in classifiers:\n",
    "    print('testing %s %s' % (str(cls), str(datetime.now())))\n",
    "    print(model_selection(X_train, y_train, X_test, y_test, cls))\n",
    "print('done %s' %  str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/todd/projects/cltk_testbed/venv/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2',\n        preprocessor=<function i...='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train all the data using a reasonable winner\n",
    "model = Pipeline([\n",
    "    ('normalizer', Doc2TokensTransformer()),\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "        analyzer='word',\n",
    "        tokenizer=identity,\n",
    "        preprocessor=identity,\n",
    "        token_pattern=None)),\n",
    "    ('classifier', SGDClassifier())\n",
    "])\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 2018-08-31 19:21:17.391585 \n"
     ]
    }
   ],
   "source": [
    "unclassified_reader = FilteredPlaintextCorpusReader(root, DOCS_TO_CLASSIFY, word_tokenizer=None,\n",
    "                                                    sent_tokenizer=None)\n",
    "to_classify_X = list(unclassified_reader.docs(unclassified_reader.fileids()))\n",
    "print('done %s ' % datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = model.predict(to_classify_X)\n",
    "print (new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'christian': ['martinbraga/superbia.txt', 'aquinas/q1.14.txt', 'innocent1.txt', 'aquinas/q1.19.txt', 'justinian/codex12.txt', 'foedusaeternum.txt', 'theodosius/theod16.txt', 'williamtyre/9.txt', 'sedulius3.txt', 'ottofreising/2.txt', 'aquinas/q1.38.txt', 'theodosius/theod14.txt', 'justinian/institutes2.txt', 'aquinas/q1.64.txt', 'capellanus/capellanus2.txt', 'mirabilia.txt', 'fulbert.txt', 'albertanus/albertanus2.txt', 'aquinas/q1.55.txt', 'martinbraga/pascha.txt', 'albertanus/albertanus.sermo3.txt', 'thomasedessa.txt', 'adso.txt', 'aquinas/q1.69.txt', 'albertanus/albertanus.arsloquendi.txt', 'voragine/chris.txt', 'baldo.txt', 'sidonius7.txt', 'voragine/alexio.txt', 'vegetius4.txt', 'gestafrancorum/gestafrancorum2.txt', 'newton.capita.txt', 'theodosius/theod05.txt', 'williamtyre/19.txt', 'egeria2.txt', 'apuleius/apuleius9.txt', 'ammianus/26.txt', 'justinian/institutes1.txt', 'aquinas/q1.51.txt', 'pauldeacon/hist3.txt', 'voragine/andrea.txt', 'aquinas/q1.32.txt', 'justinian/digest3.txt', 'censorinus.txt', 'agnes.txt', 'albertanus/albertanus.sermo.txt', 'aquinas/ente.txt', 'sha/alexsev.txt', 'sedulius1.txt', 'justinian/digest42.txt', 'walter/walter2.txt', 'aquinas/q1.50.txt', 'theodosius/theod09.txt', 'capellanus/capellanus3.txt', 'richerus3.txt', '1644.txt', 'angilbert.txt', 'aquinas/q1.47.txt', 'ep.priapismo.txt', 'oratio.stephani.txt', 'fabe.txt', 'albertofaix/hist6.txt', 'sha/claud.txt', 'iamdulcis.txt', 'ottofreising/1.txt', 'sha/firmus.txt', 'justinian/digest6.txt', 'theodosius/theod01.txt', 'walter6.txt', 'justinian/digest9.txt', 'albertanus/albertanus3.txt', 'aquinas/expositio.txt', 'voragine/ant.txt', 'arnobius/arnobius5.txt', 'thesauro.txt', 'albertofaix/hist2.txt', 'carmensaliare.txt', 'andecavis.txt', 'exivi.txt', 'abbofloracensis.txt', 'henry1.txt', 'dicquid.txt', 'martinbraga/poems.txt', 'aquinas/q1.40.txt', 'richerus4.txt', 'declaratio.txt', 'venantius.txt', 'sha/com.txt', 'apuleius/apuleius.cupid.txt', 'pulchracomis.txt', 'justinian/codex2.txt', 'martinbraga/concilium1.txt', 'williamtyre/5.txt', 'williamtyre/4.txt', 'vicentius.txt', 'apuleius/apuleius.deosocratis.txt', 'ammianus/14.txt', 'epitomecononiana.txt', 'voragine/jud.txt', 'gregdecretals4.txt', 'sedulius4.txt', 'aquinas/q1.12.txt', 'justinian/digest4.txt', 'annalesregnifrancorum.txt', 'nithardus3.txt', 'walter5.txt', 'aquinas/q1.33.txt', 'paulinus.ausonium.txt', 'aquinas/q1.35.txt', 'albertofaix/hist4.txt', 'bebel.txt', 'catalogueliberien.txt', 'walter11.txt', 'aquinas/q1.13.txt', 'gravissimas.txt', 'luther.praef.txt', 'sha/mac.txt', 'justinian/digest21.txt', 'sigebert.vitabrevior.txt', 'sidonius9.txt', 'aquinas/q1.27.txt', 'patricius2.txt', 'voragine/georgio.txt', 'apuleius/apuleius2.txt', 'justinian/digest41.txt', 'malaterra4.txt', 'apuleius/apuleius.dog1.txt', 'aquinas/q1.59.txt', 'arnobius/arnobius1.txt', 'mirandola/oratio.txt', 'aquinas/q1.34.txt', 'testamentum.txt', 'williamtyre/3.txt', 'justinian/codex9.txt', 'aquinas/q1.56.txt', 'justinian/digest43.txt', 'albertofaix/hist1.txt', 'liberpontificalis1.txt', 'justinian/digest49.txt', 'aquinas/prologus.txt', 'walter/walter1.txt', 'debury.txt', 'justin/44.txt', 'fortunat.txt', 'pauldeacon/histrom16.txt', 'histbrit.txt', 'ammianus/22.txt', 'williamtyre/12.txt', 'aquinas/q1.42.txt', 'malaterra1.txt', 'avienus.ora.txt', 'albertofaix/hist11.txt', 'aquinas/q1.83.txt', 'sigebert.virgin.txt', 'nithardus2.txt', 'ammianus/30.txt', 'septsap.txt', 'martinbraga/capitula.txt', 'aquinas/q1.68.txt', 'theodosius/theod08.txt', 'sha/marcant.txt', 'apuleius/apuleius4.txt', 'andreasbergoma.txt', 'lhomond.historiae.txt', 'voragine/thom.txt', 'justinian/institutes3.txt', 'aquinas/q1.70.txt', 'inquisitio.txt', 'sidonius5.txt', 'justinian/codex5.txt', 'williamtyre/17.txt', 'voragine/silv.txt', 'justinian/digest24.txt', 'arnobius/arnobius3.txt', 'vitacaroli.txt', 'hrabanus.txt', 'albertofaix/hist7.txt', 'gestafrancorum/gestafrancorum3.txt', 'justinian/digest20.txt', 'theodosius/theod15.txt', 'quum.txt', 'gestafrancorum/gestafrancorum5.txt', 'theodolus.txt', 'justinian/codex8.txt', 'albertofaix/hist3.txt', 'aquinas/q1.26.txt', 'voragine/iacob.txt', 'sha/clod.txt', 'aquinas/q1.43.txt', 'bill.rights.txt', 'theodosius/theod04.txt', 'ammianus/23.txt', 'tunger.txt', 'gestafrancorum/gestafrancorum1.txt', 'petrarchmedicus.txt', 'leo1.txt', 'henry3.txt', 'ottofreising/3.txt', 'mapps1.txt', 'ammianus/27.txt', 'ammianus/29.txt', 'theodosius/theod10.txt', 'waltarius3.txt', 'walter4.txt', 'epistaustras.txt', 'sha/ant.txt', 'walter9.txt', 'justinian/digest27.txt', 'prosperus.sententiae.txt', 'frontinus/contro.txt', 'bernardcluny1.txt', 'protospatarius.txt', 'histapoll.txt', 'justinian/digest48.txt', 'avianus.txt', 'justinian/digest18.txt', 'justinian/digest14.txt', 'voragine/ambro.txt', 'albertofaix/hist8.txt', 'alfonsi.disciplina.txt', 'apuleius/apuleius8.txt', 'voragine/vin.txt', 'anon.deramis.txt', 'malaterra3.txt', 'aquinas/epist.txt', 'raoul.txt', 'aquinas/corpuschristi.txt', 'justinian/digest40.txt', 'omnegenus.txt', 'aquinas/q1.18.txt', 'aquinas/q1.57.txt', 'aquinas/q1.29.txt', 'justinian/codex10.txt', 'kalila.txt', 'williamtyre/13.txt', 'columba1.txt', 'voragine/anast.txt', 'gregdecretals2.txt', 'justinian/codex6.txt', 'sedulius2.txt', 'innocent2.txt', 'justinian/institutes.proem.txt', 'arbroath.txt', 'justinian/digest39.txt', 'valesianus2.txt', 'gestarom.txt', 'williamtyre/prologus.txt', 'ammianus/31.txt', 'aquinas/q1.81.txt', 'theophanes.txt', 'aquinas/q1.62.txt', 'theodosius/theod06.txt', 'albertanus/albertanus.liberconsol.txt', 'leo3.txt', 'voragine/iul.txt', 'voragine/mariamag.txt', 'brevechronicon.txt', 'donation.txt', 'magnacarta.txt', 'ottofreising/epistola.txt', 'justinian/codex3.txt', 'pauldeacon/carmina.txt', 'columba2.txt', 'martinbraga/trina.txt', 'walter/walter3.txt', 'voragine/marc.txt', 'sidonius4.txt', 'aquinas/q1.74.txt', 'iordanes2.txt', 'sha/gord.txt', 'pauldeacon/histrom14.txt', 'piccolomini.turcos.txt', 'albertanus/albertanus.sermo1.txt', 'sha/pert.txt', 'walter10.txt', 'iordanes1.txt', 'falcone.txt', 'sha/30.txt', 'vegetius1.txt', 'don.txt', 'albertofaix/hist9.txt', 'marcellinus2.txt', 'sedulius5.txt', 'apuleius/apuleius5.txt', 'hebet.txt', 'aquinas/q1.66.txt', 'luther.95.txt', 'frontinus/lim.txt', 'capellanus/capellanus1.txt', 'aquinas/q1.39.txt', 'marcellinus1.txt', 'sigebert.script.txt', 'justin/40.txt', 'pauldeacon/histrom1.txt', 'voragine/blas.txt', 'pauldeacon/histrom13.txt', 'justinian/codex1.txt', 'patricius1.txt', 'ammianus/18.txt', 'aquinas/q1.20.txt', 'sulpiciusseveruschron1.txt', 'justinian/digest38.txt', 'psplato.iusto.txt', 'pauldeacon/hist6.txt', 'sha/avid.txt', 'prosperus.epistola.txt', 'dumdomus.txt', 'diravi.txt', 'justinian/digest25.txt', 'aquinas/q1.1.txt', 'justinian/codex11.txt', 'terraiam.txt', 'apuleius/apuleius1.txt', 'aquinas/q1.60.txt', 'archpoet.txt', 'voragine/paulo.txt', 'walter/pastourelles.txt', 'theodosius/theod07.txt', 'arnobius/arnobius4.txt', 'xanten.txt', 'justinian/institutes4.txt', 'albertofaix/hist12.txt', 'aquinas/q1.3.txt', 'notitia2.txt', 'vegetius2.txt', 'piccolomini.ep6.txt', 'apuleius/apuleius7.txt', 'sulpiciusseverusmartin.txt', 'justinian/digest5.txt', 'sha/aelii.txt', 'justinian/digest34.txt', 'albertanus/albertanus.sermo2.txt', 'mirabilia1.txt', 'piccolomini.ep5.txt', 'walter8.txt', 'aquinas/q1.72.txt', 'williamtyre/18.txt', 'williamtyre/10.txt', 'pauldeacon/hist4.txt', 'aquinas/q1.31.txt', 'aquinas/q1.24.txt', 'malaterra2.txt', 'aquinas/q1.53.txt', 'justinian/digest2.txt', 'albertofaix/hist10.txt', 'gestafrancorum/gestafrancorum6.txt', 'gregdecretals5.txt', 'wmconchesdogma.txt', 'gregdecretals3.txt', 'maidstone.txt', 'luther.lteramus.txt', 'apuleius/apuleius6.txt', 'henry2.txt', 'justinian/digest19.txt', 'minucius.txt', 'apuleius/apuleius.mundo.txt', 'balde2.txt', 'justinian/digest16.txt', 'theodosius/theod02.txt', 'annalesvedastini.txt', 'theodosius/theod11.txt', 'justin/praefatio.txt', 'mapps2.txt', 'aquinas/p1.txt', 'aquinas/q1.61.txt', 'hydatiuschronicon.txt', 'waltarius2.txt', 'tempusest.txt', 'pauldeacon/histrom15.txt', 'justinian/digest26.txt', 'ammianus/28.txt', 'pauldeacon/hist2.txt', 'zonaras.txt', 'scottus.txt', 'nithardus4.txt', 'aquinas/q1.28.txt', 'justinian/digest1.txt', 'lactantius/divinst1.txt', 'potatores.txt', 'gaud.txt', 'williamtyre/23.txt', 'ency.fides.txt', 'apuleius/apuleius.florida.txt', 'wmconchesphil.txt', 'justinian/digest37.txt', 'paris.txt', 'justinian/digest17.txt', 'arnulf.txt', 'nithardus1.txt', 'ammianus/20.txt', 'albertofaix/hist5.txt', 'godfrey.epigrammatahist.txt', 'aquinas/q1.71.txt', 'justinian/digest50.txt', 'voragine/fran.txt', 'erchempert.txt', 'porphyrius.txt', 'gestafrancorum/gestafrancorum8.txt', 'aquinas/q1.73.txt', 'williamtyre/21.txt', 'prosperus.rufinum.txt', 'sha/max.txt', 'blesensis.txt', 'williamtyre/22.txt', 'albertanus/albertanus.sermo4.txt', 'aquinas/q1.65.txt', 'celtis.oratio.txt', 'williamtyre/15.txt', 'sha/val.txt', 'sha/car.txt', 'sedulius.solis.txt', 'ammianus/15.txt', 'ammianus/24.txt', 'gestafrancorum/gestafrancorum9.txt', 'ammianus/25.txt', 'forsett1.txt', 'voragine/seb.txt', 'aquinas/q1.30.txt', 'aquinas/q1.37.txt', 'sha/geta.txt', 'justinian/digest47.txt', 'aelredus.txt', 'ammianus/21.txt', 'owen.txt', 'pauldeacon/hist5.txt', 'aquinas/q1.9.txt', 'hydatiusfasti.txt', 'voragine/vir.txt', 'voragine/luc.txt', 'apuleius/apuleius11.txt', 'williamtyre/7.txt', 'frodebertus.txt', 'ferraria.txt', 'suscipeflos.txt', 'oresmius.txt', 'passerat.txt', 'musavenit.txt', 'williamtyre/20.txt', 'godfrey.epigrammata.txt', 'aquinas/q1.8.txt', 'ammianus/19.txt', 'voragine/nic.txt', 'aquinas/q1.48.txt', 'leo2.txt', 'justinian/digest22.txt', 'williamtyre/11.txt', 'sha/aurel.txt', 'aquinas/q1.23.txt', 'theodosius/theod12.txt', 'walton.txt', 'aquinas/q1.67.txt', 'martinbraga/sententiae.txt', 'theodosius/theod13.txt', 'ein.txt', 'fragmentumlaurentianum.txt', 'justinian/digest7.txt', 'lucernarium.txt', 'aquinas/q1.41.txt', 'gregdecretals1.txt', 'gestafrancorum/gestafrancorum7.txt', 'prataiam.txt', 'justinian/codex7.txt', 'sulpiciusseveruschron2.txt', 'arnobius/arnobius2.txt', 'precatio.txt', 'martinbraga/concilium2.txt', 'martinbraga/rusticus.txt', 'richerus2.txt', 'williamtyre/14.txt', 'albertanus/albertanus4.txt', 'gioacchino.txt', 'levis.txt', 'martinbraga/repellenda.txt', 'celtis.odes.txt', 'colman.txt', 'justinian/digest29.txt', 'pauldeacon/hist1.txt', 'egeria1.txt', 'aquinas/princ.txt', 'albertanus/albertanus1.txt', 'justinian/digest32.txt', 'sidonius6.txt', 'frontinus/qualitate.txt', 'dicchristi.txt', 'aquinas/q1.63.txt', 'aquinas/q1.22.txt', 'legenda.stephani.txt', 'aquinas/q1.36.txt', 'epitomefeliciana.txt', 'sha/probus.txt', 'asserius.txt', 'bernardcluny2.txt', 'planctus.txt', 'justinian/digest12.txt', 'solet.txt', 'falcandus.txt', 'johannes.txt', 'theganus.txt', 'voragine/marina.txt', 'williamtyre/6.txt', 'williamtyre/2.txt', 'origo.txt', 'voragine/septem.txt', 'justinian/digest10.txt', 'apuleius/apuleius3.txt', 'ottofreising/4.txt', 'theodosius/theod03.txt', 'sha/diad.txt', 'lactantius/demort.txt', 'gestafrancorum/gestafrancorum4.txt', 'rhetores.txt', 'walter12.txt', 'williamtyre/8.txt', 'aquinas/q1.52.txt', 'justinian/digest15.txt', 'williamtyre/1.txt', 'gestafrancorum/gestafrancorum10.txt', 'justinian/codex4.txt', 'williamtyre/16.txt', 'justinian/digest44.txt', 'prec.terr.txt', 'fredegarius.txt', 'martinbraga/exhortatio.txt', 'arnobius/arnobius7.txt', 'carmeninvictoriam.txt', 'justinian/digest13.txt', 'aquinas/q1.21.txt', 'sha/helio.txt', 'justinian/digest11.txt'], 'old': ['carmenarvale.txt', 'scaliger.txt', 'poree.txt', 'simedignetur.txt', 'volovirum.txt'], 'augustan': ['justin/23.txt', 'nemesianus1.txt', 'victor.origio.txt', 'navagero.txt', 'janus1.txt', 'scbaccanalibus.txt', 'lhomond.viris.txt', 'prop3.txt', 'cinna.txt', 'pauldeacon/histrom4.txt', 'pascoli.catull.txt', 'justin/25.txt', 'frontinus/strat3.txt', 'eutropius/eutropius1.txt', 'justin/12.txt', 'victor.ill.txt', 'sannazaro1.txt', 'maximianus.txt', 'justin/14.txt', 'justin/16.txt', 'garland.txt', 'letabundus.txt', 'mirandola/mir1.txt', 'balbus.txt', 'justin/prologi.txt', 'corvinus2.txt', 'appvergculex.txt', 'vegius.txt', 'mirandola/mir4.txt', 'eugenius.txt', 'priapea.txt', 'balde1.txt', 'justin/13.txt', 'sha/didiul.txt', 'mirandola/mir9.txt', 'frontinus/strat4.txt', 'justin/35.txt', 'ruaeus.txt', 'justin/17.txt', 'ave.phoen.txt', 'mirandola/mir3.txt', 'justin/32.txt', 'eutropius/eutropius2.txt', 'dares1.txt', 'appvergcomp.txt', 'justin/26.txt', 'dumestas.txt', 'prop4.txt', 'valesianus.txt', 'cato/cato.agri.txt', 'justin/43.txt', 'eutropius/eutropius5.txt', 'dares.txt', 'justinian/digest8.txt', 'pauldeacon/histrom3.txt', 'justin/22.txt', 'justin/34.txt', 'naevius.txt', 'germanicus.txt', 'justin/42.txt', 'sabinus1.txt', 'mirandola/mir2.txt', 'lotichius.txt', 'pervig.txt', 'frontinus/aqua2.txt', 'sabinus2.txt', 'pauldeacon/histrom5.txt', 'ampelius.txt', 'corvinus1.txt', 'justin/33.txt', 'justin/39.txt', 'obsequens.txt', 'epitaphs.txt', 'appverg.ciris.txt', 'boskovic.txt', 'justin/29.txt', 'justin/7.txt', 'frontinus/strat1.txt', 'sabinus3.txt', 'justin/24.txt', 'justin/21.txt', 'pontano.txt', 'pascoli.sen.txt', 'eutropius/eutropius3.txt', 'pascoli.iug.txt', 'janus2.txt', 'justin/9.txt', 'nemesianus3.txt', 'justin/1.txt', 'justin/28.txt', 'justin/30.txt', 'montanus.txt', 'nemesianus2.txt', 'marullo.txt', 'calpurniussiculus.txt', 'mirandola/mir8.txt', 'dulcesolum.txt', 'justin/36.txt', 'prop2.txt', 'appverg.catalepton.txt', 'pauldeacon/histrom2.txt', 'justin/20.txt', 'eutropius/eutropius4.txt', 'inscriptions.txt', 'justin/18.txt', 'piccolomini.carmen.txt', 'justin/27.txt', 'frontinus/mensoria.txt', 'nemesianus4.txt', 'frontinus/strat2.txt', 'aus.mos.txt', 'pascoli.laur.txt', 'ilias.txt', 'justin/31.txt', 'smarius.txt', 'tevigilans.txt', 'ebulo.txt'], 'neo_latin': ['notitia1.txt', 'withof4.txt', 'psplato.halcyon.txt', 'newton.regulae.txt', 'rimbaud.txt', 'mirandola/mir6.txt', 'holberg.txt', 'withof5.txt', 'alanus/alanus2.txt', 'sicmeafata.txt', 'mirandola/mir5.txt', 'vico.orat6.txt', 'williamapulia.txt', 'columbus.txt', 'sannazaro2.txt', 'pascoli.veianius.txt', 'withof.txt', 'landor1795.txt', 'landor.1858.txt', 'halley.txt', 'alanus/alanus1.txt', 'cotta.txt', 'newton.leges.txt', 'withof1.txt', 'waltarius1.txt', 'iabervocius.txt', 'nobilis.txt', 'newton.scholium.txt', 'mirandola/mir7.txt', 'psplato.minos.txt', 'biggs.txt', 'waardenburg.txt', 'landor1810.txt', 'richerus1.txt', 'hipp.txt', 'jfkhonor.txt', 'garcilaso.txt', 'nivis.txt', 'buchanan.txt', 'landor1806.txt', 'withof2.txt', 'forsett2.txt', 'gauss.txt', 'fletcher.txt', 'milton.quintnov.txt', 'justin/8.txt', 'withof7.txt', 'withof6.txt', 'dumdiane.txt', 'withof3.txt', 'vida.txt'], 'early_silver': ['gwinne5.1.txt', 'claudian/claudian.proserp2.txt', 'frontinus/aqua1.txt', 'solinus4a.txt', 'justinian/digest45.txt', 'gwinne5.3.txt', 'gwinne3.txt', 'avienus.periegesis.txt', 'martinbraga/formula.txt', 'comes.txt', 'justin/11.txt', 'gaius3.txt', 'solinus4.txt', 'sidonius1.txt', 'curtius/curtius7.txt', 'sidonius2.txt', 'gwinne5.2.txt', 'martinbraga/ira.txt', 'pomponius1.txt', 'justinian/digest46.txt', 'solinus2a.txt', 'curtius/curtius5.txt', 'justinian/digest23.txt', 'piccolomini.ep4.txt', 'rutilius.txt', 'caeciliusbalbus.txt', 'appverg.aetna.txt', 'justinian/digest36.txt', 'curtius/curtius3.txt', 'justin/38.txt', 'aus.sept.sent.txt', 'curtius/curtius10.txt', 'ammianus/17.txt', 'claudian/claudian.ruf1.txt', 'solinus3.txt', 'cato.dis.txt', 'sidonius3.txt', 'syrus.txt', 'pomponius3.txt', 'pauldeacon/fabulae.txt', 'solinus1.txt', 'index.txt', 'pomponius2.txt', 'curtius/curtius4.txt', 'curtius/curtius9.txt', 'vegetius3.txt', 'ammianus/16.txt', 'claudian/claudian.proserp1.txt', 'grattius.txt', 'gwinne1.txt', 'solinus2.txt', 'calpurniusflaccus.txt', 'solinus3a.txt', 'justinian/digest28.txt', 'curtius/curtius8.txt', 'apuleius/apuleius10.txt', 'gwinne4.txt', 'gwinne5.4.txt', 'claudian/claudian.olyb.txt', 'justinian/digest33.txt', 'florus2.txt', 'justinian/digest31.txt', 'justin/41.txt', 'florus1.txt', 'solinus1a.txt', 'curtius/curtius6.txt', 'claudian/claudian.cons6.txt', 'claudian/claudian.proserp3.txt', 'solinus5.txt', 'reposianus.txt', 'piccolomini.ep3.txt', 'sidonius8.txt', 'justinian/digest35.txt', 'justinian/digest30.txt', 'gwinne2.txt'], 'republican': ['psplato.sisyphus.txt', 'marx.txt', 'poggio.txt', 'psplato.virtu.txt', 'sha/pesc.txt', 'gaius1.txt', 'psplato.amatores.txt', 'psplato.eryxias.txt', 'arnobius/arnobius6.txt', 'justin/2.txt', 'more.txt', 'marbodus.txt', 'clitophon.txt', 'asconius.txt', 'apuleius/apuleius.dog2.txt', 'sha/tacitus.txt', 'psplato.demodocus.txt', 'justin/6.txt', 'fronto.txt', 'justin/19.txt', 'cato/cato.frag.txt', 'justin/5.txt', 'justin/3.txt', 'victor.caes.txt', 'axio.txt', 'apuleius/apuleius.apol.txt', 'claud.inscr.txt', 'sha/maxbal.txt', 'ficino.txt', 'justin/10.txt', 'rutiliuslupus.txt', 'gaius2.txt', 'gaius4.txt'], 'medieval': ['aquinas/q1.7.txt', 'aquinas/q1.45.txt', 'aquinas/q1.5.txt', 'aquinas/q1.80.txt', 'aquinas/q1.82.txt', 'aquinas/q1.46.txt', 'aquinas/q1.17.txt', 'rumor.txt', 'anon.nev.txt', 'aquinas/q1.10.txt', 'estas.txt', 'aquinas/q1.25.txt', 'aquinas/q1.6.txt', 'henrysettimello.txt', 'aquinas/q1.58.txt', 'aquinas/q1.2.txt', 'aquinas/q1.87.txt', 'aquinas/q1.54.txt', 'aquinas/q1.16.txt', 'walter7.txt', 'aquinas/q1.4.txt', 'aquinas/q1.86.txt', 'piccolomini.ep2.txt', 'aquinas/q1.44.txt', 'piccolomini.ep1.txt', 'aquinas/q1.49.txt', 'vestiunt.txt', 'aquinas/q1.15.txt', 'aquinas/q1.11.txt', 'ipsavivere.txt'], 'late_silver': ['justin/37.txt', 'pauldeacon/histrom7.txt', 'eutropius/eutropius10.txt', 'eutropius/eutropius9.txt', 'eutropius/eutropius6.txt', 'sha/hadr.txt', 'justin/15.txt', 'pauldeacon/histrom8.txt', 'sha/carus.txt', 'pauldeacon/histrom6.txt', 'indices.txt', 'victor.caes2.txt', 'justin/4.txt', 'pauldeacon/histrom9.txt', 'eutropius/eutropius7.txt', 'sha/gall.txt', 'pauldeacon/histrom12.txt', 'eutropius/eutropius8.txt', 'pauldeacon/histrom10.txt', 'pauldeacon/histrom11.txt', 'sha/verus.txt', 'valesianus1.txt', 'sha/sepsev.txt']})\n"
     ]
    }
   ],
   "source": [
    "new_cats = defaultdict(list)\n",
    "for idx, filename in enumerate(DOCS_TO_CLASSIFY):\n",
    "    new_cats[label_encoder.classes_[new_labels[idx]]].append(filename)\n",
    "\n",
    "print(new_cats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.expanduser('~/projects/mycltk/mycltk_experiments/new_cats.json'), mode='w',\n",
    "          encoding='utf8') as writer:\n",
    "    json.dump(new_cats, writer, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.expanduser('~/projects/mycltk/mycltk_experiments/latin_text_classifier.mdl.pkl')\n",
    "        , 'wb') as writer:\n",
    "    pickle.dump(new_cats, writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
