{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Duplicate Documents\n",
    "in this notebook we will use the Text_Deduplicater utility class to:\n",
    "* find problematic texts in a single corpus\n",
    "* compare texts for different corpora \n",
    "* build a large corpus by merging several distinct corpora and excluding duplicate documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "from cltk.corpus.readers import get_corpus_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect\n",
    "from pathlib import Path \n",
    "currentdir = Path.cwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "from mlyoucanuse.text_deduplicater import TextDeduplicater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to install the tesserae corpora\n",
    "# from cltk.corpus.utils.importer import CorpusImporter\n",
    "# corpus_importer = CorpusImporter('latin')\n",
    "# #corpus_importer.list_corpora\n",
    "# corpus_importer.import_corpus('latin_text_tesserae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our Corpus readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perseus_latin_reader = get_corpus_reader(corpus_name='latin_text_perseus', language='latin')\n",
    "latin_library_reader = get_corpus_reader(corpus_name='latin_text_latin_library', language='latin')\n",
    "tesserae_reader = get_corpus_reader(corpus_name='latin_text_tesserae', language='latin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our Text Deduplicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduper = TextDeduplicater()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple proof of the Dedupe functionality\n",
    "Add Caesar docs and pick one of the files at random and add it as a duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caesar/alex.txt', 'caesar/bc1.txt', 'caesar/bc2.txt', 'caesar/bc3.txt', 'caesar/bellafr.txt', 'caesar/gall1.txt', 'caesar/gall2.txt', 'caesar/gall3.txt', 'caesar/gall4.txt', 'caesar/gall5.txt', 'caesar/gall6.txt', 'caesar/gall7.txt', 'caesar/gall8.txt', 'caesar/hisp.txt', 'suetonius/suet.caesar.txt', 'xylander/caesar.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202c51fd3c414617b3213c0d9f531aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique doc names: ['caesar/gall8.txt', 'caesar/hisp.txt', 'caesar/gall1.txt', 'caesar/bc3.txt', 'suetonius/suet.caesar.txt', 'xylander/caesar.txt', 'caesar/gall5.txt', 'caesar/bc2.txt', 'caesar/bc1.txt', 'caesar/alex.txt', 'caesar/bellafr.txt', 'caesar/gall7.txt', 'caesar/gall6.txt', 'caesar/gall3.txt', 'caesar/gall2.txt', 'caesar/gall4.txt']\n",
      "Duplicate doc names: [('caesar/bc3.txt', 'caesar/bc3.txt')]\n"
     ]
    }
   ],
   "source": [
    "caesar = [file for  file in latin_library_reader._fileids if 'caesar' in file]\n",
    "print(caesar)\n",
    "deduper = TextDeduplicater()\n",
    "for file in tqdm_notebook(caesar):\n",
    "    text = list(latin_library_reader.docs( file ))[0]\n",
    "    deduper.add_document(file, text)\n",
    "dupe_file = random.choice(caesar)\n",
    "text = list(latin_library_reader.docs(dupe_file ))[0]\n",
    "deduper.add_document(dupe_file, text)\n",
    "print(f'Unique doc names: {deduper.get_unique_doc_names()}')\n",
    "print(f'Duplicate doc names: {deduper.get_possible_duplicate_doc_names()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check the whole corpus contents\n",
    "if a file has warnings about no trigrams found, it's an indicator that the file is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94f03cb6c8e492fb2e123498b6813a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2141), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mlyoucanuse.text_deduplicater:No trigrams found for celtis.oratio.txt\n",
      "WARNING:mlyoucanuse.text_deduplicater:No trigrams found for dicchristi.txt\n",
      "WARNING:mlyoucanuse.text_deduplicater:No trigrams found for dulcesolum.txt\n",
      "WARNING:mlyoucanuse.text_deduplicater:No trigrams found for dumestas.txt\n",
      "WARNING:mlyoucanuse.text_deduplicater:No trigrams found for ency.fides.txt\n",
      "WARNING:mlyoucanuse.text_deduplicater:No trigrams found for luther.praef.txt\n",
      "WARNING:mlyoucanuse.text_deduplicater:No trigrams found for nivis.txt\n",
      "WARNING:mlyoucanuse.text_deduplicater:No trigrams found for vestiunt.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Reset the duplicator\n",
    "deduper = TextDeduplicater()\n",
    "\n",
    "for file in tqdm_notebook(latin_library_reader._fileids):\n",
    "    text = list(latin_library_reader.docs(file))[0]\n",
    "    deduper.add_document(file, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise, some problematic files just in one Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lucan/lucan7.txt', 'lucan/lucan8.txt'),\n",
       " ('albertanus/albertanus.sermo4.txt', 'albertanus/albertanus.sermo3.txt'),\n",
       " ('albertanus/albertanus.sermo1.txt', 'albertanus/albertanus.sermo3.txt'),\n",
       " ('albertanus/albertanus.sermo2.txt', 'albertanus/albertanus.sermo1.txt'),\n",
       " ('albertanus/albertanus.sermo1.txt', 'albertanus/albertanus.sermo4.txt'),\n",
       " ('albertanus/albertanus.sermo2.txt', 'albertanus/albertanus.sermo4.txt'),\n",
       " ('albertanus/albertanus.sermo3.txt', 'albertanus/albertanus.sermo2.txt')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_problematic_files = deduper.get_possible_duplicate_doc_names()\n",
    "latin_lib_problematic_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check their similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate documents and similarity scores\n",
      "lucan/lucan7.txt lucan/lucan8.txt 0.9987385682749921\n",
      "albertanus/albertanus.sermo4.txt albertanus/albertanus.sermo3.txt 1.0\n",
      "albertanus/albertanus.sermo1.txt albertanus/albertanus.sermo3.txt 1.0\n",
      "albertanus/albertanus.sermo2.txt albertanus/albertanus.sermo1.txt 1.0\n",
      "albertanus/albertanus.sermo1.txt albertanus/albertanus.sermo4.txt 1.0\n",
      "albertanus/albertanus.sermo2.txt albertanus/albertanus.sermo4.txt 1.0\n",
      "albertanus/albertanus.sermo3.txt albertanus/albertanus.sermo2.txt 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Duplicate documents and similarity scores')\n",
    "for doc_one, doc_two in latin_lib_problematic_files:\n",
    "    print(doc_one, doc_two,  \n",
    "    deduper.calculate_similarity( \n",
    "    list(latin_library_reader.docs(doc_one))[0],\n",
    "    list(latin_library_reader.docs(doc_two))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: the reported duplicate files are actually errors in the corpus\n",
    "The Lucan file is nearly the same file twice, somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucan Liber VII M. ANNAEI LVCANI BELLI CIVILIS LIBER SEPTIMVS Segnior, Oceano quam lex aeterna uocabat, luctificus Titan numquam magis aethera contra egit equos cursumque p\n",
      "Lucan Liber VIII M. ANNAEI LVCANI BELLI CIVILIS LIBER OCTAVVS Segnior, Oceano quam lex aeterna uocabat, luctificus Titan numquam magis aethera contra egit equos cursumque\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n",
      "Albertano of Brescia [an error occurred while processing this directive] The Classics Page\n"
     ]
    }
   ],
   "source": [
    "for file_one, file_two in latin_lib_problematic_files:\n",
    "    print(re.sub('\\s+',' ', list(latin_library_reader.docs(file_one))[0][:200]))\n",
    "    print(re.sub('\\s+',' ', list(latin_library_reader.docs(file_two))[0][:200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's merge the tuples so we can skip these later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lucan/lucan7.txt',\n",
       " 'albertanus/albertanus.sermo4.txt',\n",
       " 'albertanus/albertanus.sermo1.txt',\n",
       " 'albertanus/albertanus.sermo2.txt',\n",
       " 'albertanus/albertanus.sermo1.txt',\n",
       " 'albertanus/albertanus.sermo2.txt',\n",
       " 'albertanus/albertanus.sermo3.txt',\n",
       " 'lucan/lucan8.txt',\n",
       " 'albertanus/albertanus.sermo3.txt',\n",
       " 'albertanus/albertanus.sermo3.txt',\n",
       " 'albertanus/albertanus.sermo1.txt',\n",
       " 'albertanus/albertanus.sermo4.txt',\n",
       " 'albertanus/albertanus.sermo4.txt',\n",
       " 'albertanus/albertanus.sermo2.txt')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files1, files2 = zip(* latin_lib_problematic_files)\n",
    "latin_lib_problematic_files = files1 + files2\n",
    "latin_lib_problematic_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a closer look at the Latin library and Perseus corpora by looking for and comparing a shared file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plautus/menaechmi.txt']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_plautus_file = [tmp for tmp in latin_library_reader._fileids if 'plautus' in tmp and 'menaechmi' in tmp]\n",
    "latin_lib_plautus_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plautus-titus-maccius__menaechmi__latin.json']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perseus_plautus_file = [tmp for tmp in perseus_latin_reader._fileids if 'plautus' in tmp and 'menaechmi' in tmp]\n",
    "perseus_plautus_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plautus-titus-maccius__menaechmi__latin.json', 'plautus/menaechmi.txt')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perseus_plautus_text = ''.join(list(perseus_latin_reader.paras(perseus_plautus_file)))\n",
    "latin_lib_plautus_text = list(latin_library_reader.docs(latin_lib_plautus_file))[0]\n",
    "tmp_deduper = TextDeduplicater()\n",
    "tmp_deduper.add_document(perseus_plautus_file[0], perseus_plautus_text)\n",
    "tmp_deduper.add_document(latin_lib_plautus_file[0], latin_lib_plautus_text)\n",
    "tmp_deduper.get_possible_duplicate_doc_names(threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plautus: Menaechmi\\n\\t\\t \\n\\t\\t \\n\\t\\t \\n\\t \\n\\t\\n \\n T. MACCI PLAVTI MENAECHMI \\n\\n \\n\\n PERSONAE \\n \\n\\n PENICVLVS PARASITVS \\nMENAECHMVS \\nMENAECHMVS (SOSICLES) \\nEROTIUM MERETRIX \\nCYLINDRUS COCVS \\nMESSENIO SERVVS \\nANCILLA \\nMATRONA \\nSENEX \\nMEDICVS\\n \\n\\n ARGVMENTVM \\n \\n\\n Mercator Siculus, quoi erant gemini filii, \\nEi surrupto altero mors optigit. \\nNomen surrepticii illi indit qui domist \\nAvos paternus, facit Maenaechmum e '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_plautus_text[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salutem primum iam a principio propitiammihi atque vobis, spectatores, nuntio.atque adeo hoc argumentum graecissat, tamenita est adulescens; ipsus escae maxumaeQua de re aut cuius rei rerum omnium?Me neque isti male fecisse mulieri, quae me arguithanc domo ab se surrupuisse atque abstulisse deierat.sí ego intra aedis huius umquam, ubi habitat, penetravi pedem ,omnium hominum exopto ut fiam miseror'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perseus_plautus_text[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Perseus corpus isn't satisfactory, so let's try merging the Latin library corpus and the Tesserae corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26692cf4796e4781b16d420558f814a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=762), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9396909787428c83ed841f4cb63176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2141), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Reset the duplicator\n",
    "deduper = TextDeduplicater()\n",
    "\n",
    "for file in tqdm_notebook(tesserae_reader._fileids):\n",
    "    text = list(tesserae_reader.texts(file))[0]\n",
    "    if len(text) > 0:\n",
    "        deduper.add_document(file, text)    \n",
    "for file in tqdm_notebook(latin_library_reader._fileids):\n",
    "    if file not in latin_lib_problematic_files:\n",
    "        text = list(latin_library_reader.docs(file))[0]\n",
    "        if len(text) > 0:\n",
    "            deduper.add_document(file, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out which files are duplicate\n",
    "Note: of course this does not exclude any files were several texts are put together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cicero/plancio.txt',\n",
       " 'texts/silius_italicus.punica.part.14.tess',\n",
       " 'texts/quintus_smyrnaeus.fall_of_troy.part.13.tess',\n",
       " 'texts/jerome.vulgate.part.35.amos.tess',\n",
       " 'lucretius/lucretius5.txt',\n",
       " 'ilias.txt',\n",
       " 'texts/tacitus.annales.part.16.tess',\n",
       " 'texts/cicero.in_vatinium.tess',\n",
       " 'texts/prudentius.psychomachia.tess',\n",
       " 'caesar/gall6.txt',\n",
       " 'texts/caesar.de_bello_gallico.part.4.tess',\n",
       " 'texts/bede.historiam_ecclesiasticam_gentis_anglorum.part.3.tess',\n",
       " 'ovid/ovid.fasti3.txt',\n",
       " 'caesar/gall2.txt',\n",
       " 'texts/cicero.de_finibus_bonorum_et_malorum.part.3.tess',\n",
       " 'texts/statius.achilleid.tess',\n",
       " 'texts/valerius_maximus.facta_et_dicta_memorabilia.part.2.tess',\n",
       " 'tacitus/tac.hist3.txt',\n",
       " 'texts/tacitus.historiae.part.2.tess',\n",
       " 'lucretius/lucretius4.txt',\n",
       " 'bible/revelation.txt',\n",
       " 'bede/bede4.txt',\n",
       " 'texts/silius_italicus.punica.part.17.tess',\n",
       " 'cicero/verres.2.5.txt',\n",
       " 'cicero/ver1.txt',\n",
       " 'texts/tacitus.annales.part.12.tess',\n",
       " 'texts/marcus_mincuius_felix.octavius.tess',\n",
       " 'texts/tacitus.annales.part.11.tess',\n",
       " 'tacitus/tac.hist1.txt',\n",
       " 'texts/jerome.vulgate.part.7.judges.tess',\n",
       " 'texts/caesar.de_bello_gallico.part.3.tess',\n",
       " 'texts/plautus.rudens.tess',\n",
       " 'ovid/ovid.ibis.txt',\n",
       " 'horace/ep.txt',\n",
       " 'texts/cicero.de_inventione.part.2.tess',\n",
       " 'lucretius/lucretius3.txt',\n",
       " 'lucretius/lucretius6.txt',\n",
       " 'texts/silius_italicus.punica.part.11.tess',\n",
       " 'texts/curtius_rufus.historiae_alexandri_magni.part.4.tess',\n",
       " 'texts/silius_italicus.punica.part.6.tess',\n",
       " 'texts/silius_italicus.punica.part.9.tess',\n",
       " 'cicero/caecilium.txt',\n",
       " 'texts/jerome.vulgate.part.15.ezra.tess',\n",
       " 'texts/valerius_maximus.facta_et_dicta_memorabilia.part.3.tess',\n",
       " 'texts/ovid.remedia_amoris.tess',\n",
       " 'texts/caesar.de_bello_gallico.part.1.tess']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes = deduper.get_possible_duplicate_doc_names()\n",
    "single_files_to_exclude = [file_one for file_one, file_two in dupes]\n",
    "single_files_to_exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can use these distinct files to build a single larger corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
